#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass classicthesis
\begin_preamble
\usepackage{algorithm,algpseudocode}
\newref{prop}{name=Proposition~,Name=Proposition~}
\newref{prob}{name=Problem~,Name=Problem~}
\newref{thm}{name=Theorem~,Name=Theorem~}
\newref{chap}{name=Chapter~,Name=Chapter~}
\newref{part}{name=Part~,Name=Part~}
\newref{remark}{name=Remark~,Name=Remark~}
\newref{algo}{name=Algorithm~,Name=Algorithm~}
\newref{lem}{name=Lemma~,Name=Lemma~}
\MakeRobust{\Call}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
theorems-chap
\end_modules
\maintain_unincluded_children false
\language american
\language_package default
\inputencoding default
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type numerical
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Inference on Distributional Data 
\begin_inset CommandInset label
LatexCommand label
name "chap:EM"

\end_inset


\end_layout

\begin_layout Standard
In this chapter, we formalize the problem of inference on distributional
 data, and develop a novel Monte Carlo expectation-maximization algorithm
 to conduct inference on such data.
\end_layout

\begin_layout Section
Stating and Formalizing the Problem
\end_layout

\begin_layout Standard
We present in this section a generalization, stated informally in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "chap:Introduction"

\end_inset

, of the problem of inference on discretely observed data from diffusion
 processes.
\end_layout

\begin_layout Subsection
The Discretely Observed Data Problem
\end_layout

\begin_layout Standard
To begin, we review the problem of inference on diffusion processes observed
 at discrete points in time.
 This is a topic of interest for many statisticians, in large part due to
 the prevalence of diffusion processes in modeling a wide range of phenomena,
 and the simultaneous unavailability of continuous observations from such
 processes in the real world.
 Consider a solution to the SDE
\begin_inset Formula 
\begin{equation}
dX_{t}=\mu_{\theta}(X_{t})dt+\sigma_{\theta}(X_{t})dW_{t},\label{eq:sde-with-theta}
\end{equation}

\end_inset

where 
\begin_inset Formula $\theta\in\Theta\subseteq\mathcal{R}^{p}$
\end_inset

 is an unknown parameter vector, 
\begin_inset Formula $W$
\end_inset

 is a Wiener process, and 
\begin_inset Formula $\mu_{\theta}$
\end_inset

 and 
\begin_inset Formula $\sigma_{\theta}$
\end_inset

 have known parametric forms up to 
\begin_inset Formula $\theta$
\end_inset

.
 Let 
\begin_inset Formula $\mathcal{X}\subseteq\mathcal{R}$
\end_inset

 be the state space of 
\begin_inset Formula $X$
\end_inset

.
 Suppose that we observe fixed values 
\begin_inset Formula $\bar{\mathbf{x}}=\{\bar{x}_{t_{1}},\dots,\bar{x}_{t_{n}}\}\in\mathcal{X}^{n}$
\end_inset

 at a collection of times 
\begin_inset Formula $\mathcal{T}=\{t_{1}<\cdots<t_{n}=1\}$
\end_inset

 where 
\begin_inset Formula $t_{1}>0$
\end_inset

.
 Then, the log-likelihood of the data 
\begin_inset Formula $\bar{\mathbf{x}}$
\end_inset

 is 
\begin_inset Formula 
\[
\ell(\theta\mid\bar{\mathbf{x}})=\sum_{i=1}^{n}\ell_{i}(\theta),
\]

\end_inset

where 
\begin_inset Formula $\ell_{i}(\theta)=\log p_{\theta,t_{i}-t_{i-1}}(\bar{x}_{t_{i-1}},\bar{x}_{t_{i}})$
\end_inset

 and 
\begin_inset Formula $p_{\theta,t}(x,y)$
\end_inset

 is the transition density associated with 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

 as usual (we assume 
\begin_inset Formula $X_{t_{0}}=x_{0}$
\end_inset

 is fixed).
 For many specifications of 
\begin_inset Formula $\mu_{\theta}$
\end_inset

 and 
\begin_inset Formula $\sigma_{\theta}$
\end_inset

, 
\begin_inset Formula $p_{\theta,t}(x,y)$
\end_inset

 is not analytically tractable, and thus likelihood-based inference on discretel
y observed data has historically been understood to be quite difficult.
 In particular, maximum likelihood estimation (MLE) has received significant
 attention in the literature, with proposed approaches ranging from 
\begin_inset CommandInset citation
LatexCommand citet
key "sahalia-2002"

\end_inset

's closed-form analytic likelihood approximations to the simulation-based
 strategies of 
\begin_inset CommandInset citation
LatexCommand citet
key "pedersen-1995"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand citet
key "durham-gallant-2002"

\end_inset

, and more recently, to imputation-based techniques advanced by 
\begin_inset CommandInset citation
LatexCommand citet
key "beskos-2006"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citet
key "sorensen-2004"

\end_inset

 offers a comprehensive survey of the range of inferential techniques used
 for the problem of discretely observed diffusions.
\end_layout

\begin_layout Subsection
From Ex-Post to Ex-Ante
\end_layout

\begin_layout Standard
We now present the central problem of this thesis.
 We can re-interpret the discretely observed data problem by supposing we
 lived at 
\begin_inset Formula $t_{0}=0$
\end_inset

, and viewing the data 
\begin_inset Formula $\bar{\mathbf{x}}$
\end_inset

 not as values of 
\begin_inset Formula $X$
\end_inset

 that have already been observed, but rather as values that 
\begin_inset Formula $X$
\end_inset

 will take on with certainty at future times 
\begin_inset Formula $\mathcal{T}$
\end_inset

 (perhaps as prophesized by an omniscient Oracle).
 Modulo philosophical and measure-theoretic subtleties, the problem has
 not changed materially: We ought to be able to conduct likelihood-based
 inference using 
\begin_inset Formula $\ell(\theta\mid\bar{\mathbf{x}}),$
\end_inset

 so long as it is available, as usual.
\end_layout

\begin_layout Standard
This ex-ante perspective allows, however, for the generalization of interest
 to this thesis.
 For we may suppose that instead of knowing the values of 
\begin_inset Formula $X$
\end_inset

 at times 
\begin_inset Formula $\mathcal{T}$
\end_inset

, we know instead the joint distribution 
\begin_inset Formula $\nu$
\end_inset

 of these values.
 Intuitively, knowing 
\begin_inset Formula $\nu$
\end_inset

 ought to reveal information that we may use to learn about the parameters
 governing the dynamics of 
\begin_inset Formula $X$
\end_inset

; on the other hand, the likelihood function is no longer well-defined,
 and how to proceed with likelihood-based inference is therefore unclear.
 We refer to 
\begin_inset Formula $\nu$
\end_inset

 as distributional data, in juxtaposition with the observed data that is
 given in the context of MLE.
\end_layout

\begin_layout Standard
The problems of inference on discretely observed data and on distributional
 data are visualized in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:mle-intuition"

\end_inset

.
 The fixed data depicted on the left should help us learn about the dynamics
 of 
\begin_inset Formula $X$
\end_inset

 through MLE (for instance, the data looks as if it contains some information
 about the drift of 
\begin_inset Formula $X$
\end_inset

).
 The distributional data on the right, then, with marginals centered at
 the fixed data, should contain at least as much information about the dynamics
 of 
\begin_inset Formula $X$
\end_inset

, if not more.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /Users/marshall/Documents/senior/thesis/figures/mle_vs_gen_ed.pdf
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:mle-intuition"

\end_inset

A visualization of the generalization of MLE on discretely observed data
 proposed in this thesis.
 The value of the process of interest at 
\begin_inset Formula $t_{0}$
\end_inset

 is fixed and indicated by a black dot on the value axis.
 The left graphic depicts a fixed set of data 
\begin_inset Formula $\bar{\mathbf{x}}$
\end_inset

 over time, on which MLE can be performed if the log-likelihood is available.
 The right graphic depicts the marginal distributions of a set of distributional
 data, where the marginal distributions are centered at 
\begin_inset Formula $\bar{\mathbf{x}}$
\end_inset

.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the remainder of this chapter, we will consider the identifiable family
 of probability measures 
\begin_inset Formula $\mathscr{\mathcal{Q}}=\{\mathbb{Q}_{\theta}\mid\theta\in\Theta\}$
\end_inset

 on the usual probability space induced by solutions to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

 with some fixed initial condition 
\begin_inset Formula $X_{0}=x_{0}$
\end_inset

.
 We let 
\begin_inset Formula $\mathbb{Q}_{\theta,X_{\mathcal{T}}}$
\end_inset

 be the law of 
\begin_inset Formula $X_{\mathcal{T}}$
\end_inset

 under 
\begin_inset Formula $\mathbb{Q}_{\theta}$
\end_inset

 with density 
\begin_inset Formula $Q_{\theta,\mathcal{T}}$
\end_inset

, and 
\begin_inset Formula $\nu$
\end_inset

 be an 
\begin_inset Formula $n$
\end_inset

-dimensional distribution on the usual probability space restricted to times
 
\begin_inset Formula $\mathcal{T}$
\end_inset

, which is absolutely continuous to 
\begin_inset Formula $\mathbb{Q}_{\theta,X_{\mathcal{T}}}$
\end_inset

 for all 
\begin_inset Formula $\theta\in\Theta$
\end_inset

.
 Then, the problem of inference on distributional data can loosely be stated
 as: What, if anything, can we say about 
\begin_inset Formula $\theta$
\end_inset

, given 
\begin_inset Formula $X_{\mathcal{T}}\sim\nu$
\end_inset

?
\end_layout

\begin_layout Subsection
Proposing and Characterizing an Estimator
\end_layout

\begin_layout Standard
In this subsection, we propose an estimator for 
\begin_inset Formula $\theta$
\end_inset

 given 
\begin_inset Formula $X_{\mathcal{T}}\sim\nu$
\end_inset

, and make some remarks characterizing its relationship to the maximum likelihoo
d estimator given discretely observed data.
\end_layout

\begin_layout Standard
We first note that from the ex-ante perspective presented above, the problem
 of discretely observed data is a special case of the problem of distributional
 data.
 Intuitively, if we were given distributional data under which 
\begin_inset Formula $X_{\mathcal{T}}$
\end_inset

 was a degenerate random variable, we would know the values that 
\begin_inset Formula $X$
\end_inset

 would take on with certainty at future times 
\begin_inset Formula $\mathcal{T}$
\end_inset

 (again, modulo philosophical and measure-theoretic subtleties).
 Then, the problem of distributional data could be solved through traditional
 MLE.
 Slightly more formally, we can fix some data 
\begin_inset Formula $\bar{\mathbf{x}}\in\mathcal{X}^{n}$
\end_inset

.
 If 
\begin_inset Formula $\{\nu_{(m)}\}$
\end_inset

 is a sequence of probability measures which are absolutely continuous to
 
\begin_inset Formula $\mathbb{Q}_{\theta,X_{\mathcal{T}}}$
\end_inset

 and which converge (in some sense) to the Dirac delta measure 
\begin_inset Formula $\delta_{\bar{\mathbf{x}}}$
\end_inset

, then as 
\begin_inset Formula $m\rightarrow\infty$
\end_inset

, any estimator for 
\begin_inset Formula $\theta$
\end_inset

 given 
\begin_inset Formula $X_{\mathcal{T}}\sim\nu_{(m)}$
\end_inset

 should coincide with the MLE given 
\begin_inset Formula $\bar{\mathbf{x}}$
\end_inset

.
 A quantity that should satisfy this criterion is 
\begin_inset Formula 
\begin{equation}
\arg\max_{\theta\in\Theta}\int\log Q_{\theta,\mathcal{T}}(x)\nu(dx).\label{eq:mklde}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
We define 
\begin_inset Formula $\Lambda_{\theta}(\nu)\coloneqq\int\log Q_{\theta,\mathcal{T}}(x)\nu(dx)$
\end_inset

, alluding with our notation to the traditional log-likelihood function
 
\begin_inset Formula $\ell_{\theta}(\bar{\mathbf{x}})$
\end_inset

.
 We note that 
\begin_inset Formula $\arg\max_{\theta\in\Theta}\Lambda_{\theta}(\nu)$
\end_inset

 is not an estimator in the technical sense since it is a functional of
 a distribution 
\begin_inset Formula $\nu$
\end_inset

, rather than a function of observed data.
 In this thesis, we will use the term 
\begin_inset Quotes eld
\end_inset

estimator
\begin_inset Quotes erd
\end_inset

 loosely to refer to any function(al) of data (distributional or otherwise)
 that is used to infer the value of an unknown parameter in a statistical
 model.
 
\end_layout

\begin_layout Standard
As 
\begin_inset CommandInset citation
LatexCommand citet
before "Section 1 in"
key "akaike-1973"

\end_inset

 notes, maximizing 
\begin_inset Formula $\Lambda_{\theta}(\nu)$
\end_inset

 is equivalent to minimizing the K-L divergence of 
\begin_inset Formula $\mathbb{Q}_{\theta,X_{\mathcal{T}}}$
\end_inset

 from 
\begin_inset Formula $\nu$
\end_inset

.
 This is easily seen by writing 
\begin_inset Formula 
\begin{eqnarray*}
D(\nu\:||\:\mathbb{Q}_{\theta,X_{\mathcal{T}}}) & = & \mathbb{E}_{\nu}\left[\log\frac{d\nu}{d\mathbb{Q}_{\theta,X_{\mathcal{T}}}}\right]\\
 & = & \mathbb{E}_{\nu}\left[\log\frac{d\nu}{dx}\right]-\mathbb{E}_{\nu}\left[\log\frac{d\mathbb{Q}_{\theta,X_{\mathcal{T}}}}{dx}\right].
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
For this reason, we call the proposed estimator for 
\begin_inset Formula $\theta$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:mklde"

\end_inset

 the minimum K-L divergence estimator (MKLDE) given 
\begin_inset Formula $\nu$
\end_inset

.
 We now present two remarks, which
\end_layout

\begin_layout aEnumerate (ClassicThesis)
characterize the MKLDE given 
\begin_inset Formula $\nu$
\end_inset

 as a limiting case of maximum likelihood estimation under model misspecificatio
n when 
\begin_inset Formula $\nu$
\end_inset

 is a true probability model, and
\end_layout

\begin_layout aEnumerate (ClassicThesis)
show that a (traditional) estimator given finitely many samples from 
\begin_inset Formula $\nu$
\end_inset

 asymptotically converges to the MKLDE given 
\begin_inset Formula $\nu$
\end_inset

.
\end_layout

\begin_layout Standard
The first remark connects the MKLDE given 
\begin_inset Formula $\nu$
\end_inset

 to the MLE under model misspecification.
\end_layout

\begin_layout Remark
\begin_inset CommandInset label
LatexCommand label
name "rem:misspecification"

\end_inset

Let 
\begin_inset Formula $\nu$
\end_inset

 be the true distribution of 
\begin_inset Formula $X$
\end_inset

 at times 
\begin_inset Formula $\mathcal{T}$
\end_inset

, and consider 
\begin_inset Formula $N$
\end_inset

 i.i.d draws from 
\begin_inset Formula $\nu$
\end_inset

, 
\begin_inset Formula $\{X_{\mathcal{T},(i)}\}_{i=1,\dots,N}$
\end_inset

.
 If we wished to model 
\begin_inset Formula $\nu$
\end_inset

 using the family of potentially misspecified probability models 
\begin_inset Formula $\mathcal{Q}$
\end_inset

 restricted to 
\begin_inset Formula $\mathcal{T}$
\end_inset

, the MLE given 
\begin_inset Formula $\{X_{\mathcal{T},(i)}\}_{i=1,\dots,N}$
\end_inset

 would be 
\begin_inset Formula 
\[
\arg\max_{\theta\in\Theta}\frac{1}{N}\sum_{i=1}^{N}\log Q_{\theta,\mathcal{T}}(X_{\mathcal{T},(i)}).
\]

\end_inset

By a result of 
\begin_inset CommandInset citation
LatexCommand citet
before "Theorem 2.2 in"
key "white-1982"

\end_inset

, 
\begin_inset Formula 
\[
\arg\max_{\theta\in\Theta}\frac{1}{N}\sum_{i=1}^{N}\log Q_{\theta,\mathcal{T}}(X_{\mathcal{T},(i)})\xrightarrow{p}\arg\min_{\theta\in\Theta}\mathbb{E}_{\nu}\left[\log\frac{d\nu}{d\mathbb{Q}_{\theta,X_{\mathcal{T}}}}\right]
\]

\end_inset

as 
\begin_inset Formula $N\rightarrow\infty$
\end_inset

, and thus by the observation of 
\begin_inset CommandInset citation
LatexCommand citet
key "akaike-1973"

\end_inset

, 
\begin_inset Formula 
\[
\arg\max_{\theta\in\Theta}\frac{1}{N}\sum_{i=1}^{N}\log Q_{\theta,\mathcal{T}}(X_{\mathcal{T},(i)})\xrightarrow{p}\arg\max_{\theta\in\Theta}\Lambda_{\theta}(\nu),
\]

\end_inset

which is the MKLDE.
\end_layout

\begin_layout Standard
The intuition for this relationship is as follows.
 Recall that a time-homogenous Markov measure is uniquely determined by
 a transition kernel and a marginal measure; an SDE satisfying the requirements
 outlined in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "chap:2"

\end_inset

 along with the initial condition 
\begin_inset Formula $X_{0}=x_{0}$
\end_inset

 therefore admits a bijection between 
\begin_inset Formula $\Theta$
\end_inset

 and 
\begin_inset Formula $\mathcal{Q}$
\end_inset

.
 Now suppose we know 
\begin_inset Formula $X_{\mathcal{T}}\sim\nu$
\end_inset

.
 If 
\begin_inset Formula $\nu$
\end_inset

 is not the law of 
\begin_inset Formula $X_{\mathcal{T}}$
\end_inset

 under any element of 
\begin_inset Formula $\mathcal{Q}$
\end_inset

, it must be the case that we have misspecified our probability model.
 In this case, the best we can do is to find the value of 
\begin_inset Formula $\theta$
\end_inset

 that minimizes the K-L divergence of 
\begin_inset Formula $\mathbb{Q}_{\theta,X_{\mathcal{T}}}$
\end_inset

 from 
\begin_inset Formula $\nu$
\end_inset

, which is precisely the MKLDE given 
\begin_inset Formula $\nu$
\end_inset

.
\end_layout

\begin_layout Standard
In practice, we will often only have access to a finite number of draws
 from 
\begin_inset Formula $\nu$
\end_inset

; think, for instance, of the forecasts for humidity that a panel of finitely
 many weatherpeople might give.
 We now remark on the consistency of the MKLDE given only a fixed number
 of samples from 
\begin_inset Formula $\nu$
\end_inset

.
\end_layout

\begin_layout Remark
\begin_inset CommandInset label
LatexCommand label
name "rem:bootstrap"

\end_inset

Let 
\begin_inset Formula $\hat{\nu}_{(N)}$
\end_inset

 be the empirical distribution function induced by 
\begin_inset Formula $N$
\end_inset

 draws from 
\begin_inset Formula $\nu$
\end_inset

, and consider 
\begin_inset Formula $N$
\end_inset

 i.i.d draws from 
\begin_inset Formula $\hat{\nu}_{(N)}$
\end_inset

, 
\begin_inset Formula $\{X_{\mathcal{T},(i)}\}_{i=1,\dots,N}$
\end_inset

.
 By standard results demonstrating the consistency of plug-in bootstrap
 estimators (see 
\begin_inset CommandInset citation
LatexCommand citet
before "Section 1 in"
key "horowitz-2002"

\end_inset

), 
\begin_inset Formula 
\begin{eqnarray*}
\Lambda_{\theta}(\hat{\nu}_{(N)}) & = & \int\log P_{\theta,\mathcal{T}}(x)\hat{\nu}_{(N)}(dx)\\
 & = & \frac{1}{N}\sum_{i=1}^{N}\log Q_{\theta,\mathcal{T}}(X_{\mathcal{T},(i)})\\
 & \xrightarrow{p} & \Lambda_{\theta}(\nu)
\end{eqnarray*}

\end_inset

and by a loose application of the 
\begin_inset Formula $\arg\max$
\end_inset

 continuous mapping theorem (see 
\begin_inset CommandInset citation
LatexCommand citet
before "Theorem 2.7 in"
key "kim-pollard-1990"

\end_inset

), 
\begin_inset Formula 
\[
\arg\max_{\theta\in\Theta}\Lambda_{\theta}(\hat{\nu}_{(N)})\xrightarrow{p}\arg\max_{\theta\in\Theta}\Lambda_{\theta}(\nu),
\]

\end_inset

which is the MKLDE given 
\begin_inset Formula $\nu$
\end_inset

.
\end_layout

\begin_layout Standard
This remark shows that an estimator for 
\begin_inset Formula $\theta$
\end_inset

 can be developed when only given finitely many samples from 
\begin_inset Formula $\nu$
\end_inset

; we simply use the empirical distribution of the samples as a plug-in estimate
 for 
\begin_inset Formula $\nu$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:mklde"

\end_inset

.
 This estimator is consistent for the true minimum K-L divergence parameter,
 and is an estimator in the traditional technical sense since 
\begin_inset Formula $\hat{\nu}$
\end_inset

, and by extension 
\begin_inset Formula $\Lambda_{\theta}(\hat{\nu})$
\end_inset

, is a function of fixed observations.
 We will simply call this estimator the MKLDE given 
\begin_inset Formula $\hat{\nu}$
\end_inset

, with the underlying data implicit, in direct analogy to the MKLDE given
 
\begin_inset Formula $\nu$
\end_inset

 defined in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:mklde"

\end_inset

, and refer to both these estimators more generally as the MKLDE.
\end_layout

\begin_layout Standard
Together, the two remarks presented above describe why 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:mklde"

\end_inset

 is statistically meaningful in the context of distributional data.
 In particular, suppose 
\begin_inset Formula $\mathbb{P}$
\end_inset

 is a true but unknown probability model, but the law of 
\begin_inset Formula $X_{\mathcal{T}}$
\end_inset

 under 
\begin_inset Formula $\mathbb{P}$
\end_inset

 is known to be 
\begin_inset Formula $\nu$
\end_inset

.
 Then, the MKDLE given 
\begin_inset Formula $\nu$
\end_inset

 over any parameterized family of probability models 
\begin_inset Formula $\mathcal{Q}$
\end_inset

 identifies the 
\begin_inset Formula $\mathbb{Q}_{\theta}\in\mathcal{Q}$
\end_inset

 such that 
\begin_inset Formula $\mathbb{Q}_{\theta,X_{\mathcal{T}}}$
\end_inset

 has the minimum K-L divergence from 
\begin_inset Formula $\nu$
\end_inset

.
 The MKLDE is furthermore asymptotically consistent when we use the empirical
 law of samples from 
\begin_inset Formula $\nu$
\end_inset

 as a plug-in estimate for 
\begin_inset Formula $\nu$
\end_inset

.
\end_layout

\begin_layout Standard
While we have shown that the MKDLE is meaningful, given the unavailability
 of a transition density for most diffusion processes, it is clear that
 
\begin_inset Formula $\Lambda_{\theta}(\nu)$
\end_inset

 has no obvious functional form for all but the most specific choices of
 
\begin_inset Formula $\mu_{\theta},\sigma_{\theta}$
\end_inset

, and 
\begin_inset Formula $\nu$
\end_inset

.
 Solving for the MKLDE is therefore impossible from an analytic standpoint;
 the next section addresses this issue by developing a simulation-based
 strategy for finding the MKLDE.
\end_layout

\begin_layout Section
Simulation-Based K-L Divergence Minimization
\end_layout

\begin_layout Standard
Simulation-based inference techniques have been applied widely in the literature
 to solve the problem of likelihood-based inference on discretely observed
 diffusions.
 This approach began with the seminal paper of 
\begin_inset CommandInset citation
LatexCommand citet
key "pedersen-1995"

\end_inset

.
 More recently, 
\begin_inset CommandInset citation
LatexCommand citet
key "roberts-stramer-2001,elerian-chib-shephard-2001"

\end_inset

, and others simultaneously realized that the problem of discrete observations
 could be framed in terms of missing data.
 In particular, though the likelihood function given discrete observations
 is in general intractable, Girsanov's formula can give the likelihood of
 the observations when they are augmented with the continuous path of the
 process in question between observations.
 
\begin_inset CommandInset citation
LatexCommand citet
key "beskos-2006"

\end_inset

, building on techniques developed by 
\begin_inset CommandInset citation
LatexCommand citet
key "dempster-1977"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand citet
key "wei-tanner-1990"

\end_inset

, show that the simulation of diffusion bridges (using the Exact Algorithm
 of 
\begin_inset CommandInset citation
LatexCommand citet
key "beskos-roberts-2005"

\end_inset

) could be leveraged to supply this missing data; this approach will be
 of particular interest to us.
\end_layout

\begin_layout Standard
In this section, we generalize the results of 
\begin_inset CommandInset citation
LatexCommand citet
key "roberts-stramer-2001,beskos-2006"

\end_inset

, and 
\begin_inset CommandInset citation
LatexCommand citet
key "bladt-sorensen-2014"

\end_inset

 to propose a simulation-based method to find the MKLDE.
 As noted above, 
\begin_inset Formula $\Lambda_{\theta}(\nu)$
\end_inset

 cannot be maximized analytically.
 However, we use the close parallels between the MLE given discretely observed
 data and the MKLDE given distributional data to develop an MCEM algorithm
 which converges to 
\begin_inset Formula $\arg\max_{\theta\in\Theta}\Lambda_{\theta}(\nu)$
\end_inset

.
\end_layout

\begin_layout Subsection
The Case of Unit Diffusion Coefficient
\end_layout

\begin_layout Standard
We will first consider the highly specific case of 
\begin_inset Formula $\sigma_{\theta}(x)$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

 being equal to unity so that we may focus deriving the general shape of
 a simulation strategy.
 In particular, we prove the central result of this chapter in this subsection,
 which gives a novel EM algorithm which maximizes 
\begin_inset Formula $\Lambda_{\theta}(\nu)$
\end_inset

 in a manner analagous to the EM algorithm of 
\begin_inset CommandInset citation
LatexCommand citet
before "Section 8 in"
key "beskos-2006"

\end_inset

, which maximizes 
\begin_inset Formula $\ell_{\theta}(\bar{\mathbf{x}})$
\end_inset

 for discretely observed data 
\begin_inset Formula $\bar{\mathbf{x}}\in\mathcal{X}^{n}$
\end_inset

.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:em"

\end_inset

Suppose 
\begin_inset Formula $\sigma_{\theta}(x)=1$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

.
 Then, let 
\begin_inset Formula $\mathcal{Q}=\{\mathbb{Q}_{\theta}\mid\theta\in\Theta\}$
\end_inset

 be the identifiable family of probability measures that are induced by
 solutions to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

 with constant initial condition.
 Fix a parameter estimate 
\begin_inset Formula $\tilde{\theta}\in\Theta$
\end_inset

 and let 
\begin_inset Formula $\nu$
\end_inset

 be a distribution satisfying the usual assumptions.
 If 
\begin_inset Formula $\mathbb{Q}_{\tilde{\theta}}^{\nu}$
\end_inset

 is the Baudoin 
\begin_inset Formula $(X_{\mathcal{T}},\nu)$
\end_inset

-conditioning of 
\begin_inset Formula $\mathbb{Q}_{\tilde{\theta}}\in\mathcal{Q}$
\end_inset

, then 
\begin_inset Formula 
\begin{equation}
\arg\max_{\theta\in\Theta}\Lambda_{\theta}(\nu)-\Lambda_{\tilde{\theta}}(\nu)=\arg\max_{\theta\in\Theta}\mathbb{E}_{\mathbb{Q}_{\tilde{\theta}}^{\nu}}\left[\int_{0}^{1}\mu_{\theta}(X_{s})dX_{s}-\frac{1}{2}\int_{0}^{1}\mu_{\theta}^{2}(X_{s})ds\right].\label{eq:em-equation}
\end{equation}

\end_inset

gives an iteration of an EM algorithm which converges to the MKLDE given
 
\begin_inset Formula $\nu$
\end_inset

.
 In particular, repeated iterations of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:em-equation"

\end_inset

 converge to the parameter 
\begin_inset Formula $\theta^{*}\in\Theta$
\end_inset

 such that the law of 
\begin_inset Formula $X_{\mathcal{T}}$
\end_inset

 under 
\begin_inset Formula $\mathbb{Q}_{\theta^{*}}$
\end_inset

 has the minimum K-L divergence from 
\begin_inset Formula $\nu$
\end_inset

, for any 
\begin_inset Formula $\mathbb{Q}_{\theta}\in\mathcal{Q}$
\end_inset

.
\end_layout

\begin_layout Proof
We begin by re-expressing the objective function on the left hand side of
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:em-equation"

\end_inset

 as 
\begin_inset Formula 
\begin{eqnarray}
\Lambda_{\theta}(\nu)-\Lambda_{\tilde{\theta}}(\nu) & = & \int\log Q_{\theta,\mathcal{T}}(x_{\mathcal{T}})\nu(dx_{\mathcal{T}})-\Lambda_{\tilde{\theta}}(\nu)\nonumber \\
 & = & \int\log\int Q_{\theta,\mathcal{T}}(x_{\mathcal{T}}\mid x)Q_{\theta}(x)dx\nu(dx_{\mathcal{T}})-\Lambda_{\tilde{\theta}}(\nu),\label{eq:firststepem}
\end{eqnarray}

\end_inset

where we take
\series bold
 
\begin_inset Formula $X$
\end_inset

 
\series default
to be missing data representing the path of a solution to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

 on 
\begin_inset Formula $[0,1]$
\end_inset

.
 Then, in a similar fashion to standard arguments in the derivation of the
 EM algorithm (see, for instance, 
\begin_inset CommandInset citation
LatexCommand citet
before "Section 3.1 in"
key "borman-2006"

\end_inset

), we can find from 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:firststepem"

\end_inset

 that
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
\Lambda_{\theta}(\nu)-\Lambda_{\tilde{\theta}}(\nu) & \geq\iint\log\left(\frac{Q_{\theta,\mathcal{T}}(x_{\mathcal{T}}\mid x)Q_{\theta}(x)}{Q_{\tilde{\theta}}(x\mid x_{\mathcal{T}})}\right)P_{\tilde{\theta}}(x\mid x_{\mathcal{T}})dx\nu(dx_{\mathcal{T}})-\Lambda_{\tilde{\theta}}(\nu)\nonumber \\
 & =\iint\log\left(\frac{Q_{\theta,\mathcal{T}}(x_{\mathcal{T}}\mid x)Q_{\theta}(x)}{Q_{\tilde{\theta}}(x\mid x_{\mathcal{T}})Q_{\tilde{\theta},\mathcal{T}}(x_{\mathcal{T}})}\right)P_{\tilde{\theta}}(x\mid x_{\mathcal{T}})dx\nu(dx_{\mathcal{T}}).\label{eq:Deltatn}
\end{align}

\end_inset

We define the quantity in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Deltatn"

\end_inset

 as 
\begin_inset Formula $\Delta(\theta\mid\tilde{\theta})$
\end_inset

, and let 
\begin_inset Formula $\mathscr{Q}(\theta\mid\tilde{\theta})\coloneqq\Lambda_{\tilde{\theta}}(\nu)+\Delta(\theta\mid\tilde{\theta})\leq\Lambda_{\theta}(\nu)$
\end_inset

.
 It can be shown by standard arguments that 
\begin_inset Formula $\mathscr{Q}(\tilde{\theta}\mid\tilde{\theta})=\Lambda_{\tilde{\theta}}(\nu$
\end_inset

), and so any 
\begin_inset Formula $\theta$
\end_inset

 that increases 
\begin_inset Formula $\mathscr{Q}(\theta\mid\tilde{\theta})$
\end_inset

 must also increase 
\begin_inset Formula $\Lambda^{\nu}(\theta)$
\end_inset

.
 To maximize this increase, it suffices to solve for
\begin_inset Formula 
\begin{eqnarray*}
\arg\max_{\theta\in\Theta}\mathscr{Q}(\theta\mid\tilde{\theta}) & = & \arg\max_{\theta\in\Theta}\iint\log\left(\frac{Q_{\theta,\mathcal{T}}(x_{\mathcal{T}}\mid x)Q_{\theta}(x)}{Q_{\tilde{\theta}}(x\mid x_{\mathcal{T}})Q_{\tilde{\theta},\mathcal{T}}(x_{\mathcal{T}})}\right)Q_{\tilde{\theta}}(x\mid x_{\mathcal{T}})dx\nu(dx_{\mathcal{T}})\\
 & = & \arg\max_{\theta\in\Theta}\iint\log Q_{\theta}(x)Q_{\tilde{\theta}}(x\mid x_{\mathcal{T}})dx\nu(dx_{\mathcal{T}})\\
 & = & \arg\max_{\theta\in\Theta}\int\log Q_{\theta}(x)\mathbb{Q}_{\tilde{\theta}}^{\nu}(dx).
\end{eqnarray*}

\end_inset

The first equality follows from dropping terms that are constant with respect
 to 
\begin_inset Formula $\theta$
\end_inset

, including 
\begin_inset Formula $Q_{\theta,\mathcal{T}}(x_{\mathcal{T}}\mid x)$
\end_inset

 since the full path 
\begin_inset Formula $x$
\end_inset

 is fixed.
 The second equality follows from the assumption of some regularity conditions
 that allow for switching the order of integration and the existence of
 the requisite densities, and from the definition of a Baudoin conditioning.
\end_layout

\begin_layout Proof
By Girsanov's theorem, since the complete path 
\begin_inset Formula $X$
\end_inset

 has unit diffusion coefficient, we may write 
\begin_inset Formula 
\[
\log Q_{\theta}(X)=\int_{0}^{1}\mu_{\theta}(X_{s})dx_{s}-\frac{1}{2}\int_{0}^{1}\mu_{\theta}^{2}(X_{s})ds,
\]

\end_inset

and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:em-equation"

\end_inset

 follows.
 As in any EM algorithm, repeated iterations of 
\begin_inset Formula $\tilde{\theta}=\arg\max_{\theta\in\Theta}Q(\theta\mid\tilde{\theta})$
\end_inset

 will converge to 
\begin_inset Formula $\arg\max_{\theta\in\Theta}\Lambda_{\theta}(\nu)$
\end_inset

, which is precisely the MKLDE.
\end_layout

\begin_layout Standard
Note that when 
\begin_inset Formula $\nu=\delta_{\bar{\mathbf{x}}}$
\end_inset

 (in some limiting sense) for fixed data 
\begin_inset Formula $\bar{\mathbf{x}}$
\end_inset

 observed at 
\begin_inset Formula $\mathcal{T}$
\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:em-equation"

\end_inset

 reduces to 
\begin_inset Formula 
\[
\arg\max_{\theta\in\Theta}\ell(\theta\mid\bar{\mathbf{x}})-\ell(\tilde{\theta}\mid\bar{\mathbf{x}})=\arg\max_{\theta}\mathbb{E}_{X\mid\bar{\mathbf{x}},\tilde{\theta}}\left[\int_{0}^{1}\mu_{\theta}(X_{s})dX_{s}-\frac{1}{2}\int_{0}^{1}\mu_{\theta}^{2}(X_{s})ds\right]
\]

\end_inset

where the expectation is taken over traditional diffusion bridges 
\begin_inset Formula $X$
\end_inset

 conditioned on 
\begin_inset Formula $\bar{\mathbf{x}}$
\end_inset

.
 This equation is simply the EM algorithm of 
\begin_inset CommandInset citation
LatexCommand citet
key "beskos-2006"

\end_inset

 for discretely observed data.
 
\end_layout

\begin_layout Standard
Though 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:em-equation"

\end_inset

 is intractable, given the ability to sample 
\begin_inset Formula $X$
\end_inset

 under 
\begin_inset Formula $\mathbb{Q}_{\tilde{\theta}}^{\nu}$
\end_inset

, it is suggestive of a Monte Carlo implementation of the EM algorithm following
 
\begin_inset CommandInset citation
LatexCommand citet
key "wei-tanner-1990"

\end_inset

.
 But before developing such an implementation, we generalize 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:em-equation"

\end_inset

 for the case of diffusion coefficients known only up to 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Subsection
Augmentation Under the Lamperti Transform
\end_layout

\begin_layout Standard
The restriction of the diffusion coefficient to unity severely reduces the
 utility of the EM algorithm in practical settings.
 In this subsection, we relax this assumption and derive an EM algorithm
 suitable for general use.
 Our general strategy to deal with a diffusion with general diffusion coefficien
t is to first transform it into one with unit diffusion coefficient.
 Then, after some further transformations, we can derive the log-likelihood
 of such a transformed process using Girsanov's theorem, and substitute
 this likelihood into 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:em-equation"

\end_inset

.
\end_layout

\begin_layout Standard
Recall that for any solution to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

, we may define the Lamperti transform 
\begin_inset Formula $\eta_{\theta}(x)$
\end_inset

, where
\begin_inset Formula 
\[
\eta_{\theta}(x)=\int_{x^{*}}^{x}\frac{1}{\sigma_{\theta}(y)}dy,
\]

\end_inset

for appropriate but otherwise arbitrary 
\begin_inset Formula $x^{*}$
\end_inset

.
 If we set 
\begin_inset Formula $Y_{t}=\eta_{\theta}(X_{t})$
\end_inset

, by Itô's lemma, 
\begin_inset Formula $Y$
\end_inset

 is the solution to the stochastic differential equation
\begin_inset Formula 
\begin{equation}
dY_{t}=\alpha_{\theta}(Y_{t})dt+dW_{t},\label{eq:eta-y}
\end{equation}

\end_inset

where 
\begin_inset Formula 
\[
\alpha_{\theta}(y)=\frac{\mu_{\theta}(\eta_{\theta}^{-1}(y))}{\sigma_{\theta}(\eta_{\theta}^{-1}(y))}-\frac{1}{2}\sigma_{\theta}^{'}(\eta_{\theta}^{-1}(y)).
\]

\end_inset

We use 
\begin_inset Formula $\mathbb{Y}_{\theta}$
\end_inset

 to denote the measure induced by a solution to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:eta-y"

\end_inset

 with constant initial condition 
\begin_inset Formula $Y_{0}=\eta_{\theta}(x_{0}).$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:eta-y"

\end_inset

 reveals that the Lamperti transform is a continuous transformation which
 reduces the diffusion coefficient of any diffusion to unity.
 However, 
\begin_inset CommandInset citation
LatexCommand citet
key "bladt-sorensen-2014"

\end_inset

 point out that under the Lamperti transform, the distribution of 
\begin_inset Formula $Y$
\end_inset

 at times 
\begin_inset Formula $\mathcal{T}$
\end_inset

 becomes dependent on the parameter 
\begin_inset Formula $\theta$
\end_inset

, while the EM algorithm requires that the given data remain fixed with
 respect to 
\begin_inset Formula $\theta$
\end_inset

.
 We adapt their proposed solution to our problem, referring the reader to
 
\begin_inset CommandInset citation
LatexCommand citet
before "Section 4.1 in"
key "bladt-sorensen-2014"

\end_inset

, who build on techniques developed in 
\begin_inset CommandInset citation
LatexCommand citet
before "Section 3.2 in"
key "roberts-stramer-2001"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand citet
before "Section 8.2 in"
key "beskos-2006"

\end_inset

, for the theoretical details of the approach.
 
\end_layout

\begin_layout Standard
Heuristically, our solution is to generate paths of 
\begin_inset Formula $Y$
\end_inset

 under 
\begin_inset Formula $\tilde{\theta}$
\end_inset

 and apply linear transformations to these paths so that they 
\begin_inset Quotes eld
\end_inset

look
\begin_inset Quotes erd
\end_inset

 like paths under 
\begin_inset Formula $\theta$
\end_inset

.
 In this way, for each iteration of the EM algorithm, the given distributional
 data remains fixed with respect to 
\begin_inset Formula $\theta$
\end_inset

.
 In particular, we consider 
\begin_inset Formula $t_{i-1}\leq t\leq t_{i}$
\end_inset

 for each 
\begin_inset Formula $i=1,\dots,n$
\end_inset

.
 Let 
\begin_inset Formula $Z(\tilde{\theta})$
\end_inset

 be a path under 
\begin_inset Formula $\mathbb{Y}_{\tilde{\theta}}^{\nu\circ\eta_{\tilde{\theta}}^{-1}}\eqqcolon\mathbb{Z}_{\tilde{\theta}}$
\end_inset

 i.e.
 a solution to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:eta-y"

\end_inset

 conditioned to follow the distribution 
\begin_inset Formula $\nu\circ\eta_{\tilde{\theta}}^{-1}$
\end_inset

 at times 
\begin_inset Formula $\mathcal{T}$
\end_inset

.
 Setting 
\begin_inset Formula $H_{\tilde{\theta}\rightarrow\theta}=\eta_{\theta}\circ\eta_{\tilde{\theta}}^{-1}$
\end_inset

, we define 
\begin_inset Formula 
\begin{eqnarray*}
Y_{t}^{*}(\theta,\tilde{\theta}) & = & Z_{t}(\tilde{\theta})+\frac{(t_{i}-t)(H_{\tilde{\theta}\rightarrow\theta}(Z_{t_{i-1}}(\tilde{\theta}))-Z_{t_{i-1}}(\tilde{\theta}))}{t_{i}-t_{i-1}}+\\
 &  & \frac{(t-t_{i-1})(H_{\tilde{\theta}\rightarrow\theta}(Z_{t_{i}}(\tilde{\theta}))-Z_{t_{i}}(\tilde{\theta}))}{t_{i}-t_{i-1}}.
\end{eqnarray*}

\end_inset

Note that 
\begin_inset Formula $Y_{t_{i-1}}^{*}(\theta,\tilde{\theta})=H_{\tilde{\theta}\rightarrow\theta}(Z_{t_{i-1}}(\tilde{\theta}))$
\end_inset

 and 
\begin_inset Formula $Y_{t_{i}}^{*}(\theta,\tilde{\theta})=H_{\tilde{\theta}\rightarrow\theta}(Z_{t_{i}}(\tilde{\theta}))$
\end_inset

; in this sense, 
\begin_inset Formula $Y_{\mathcal{T}}^{*}$
\end_inset

 
\begin_inset Quotes eld
\end_inset

looks
\begin_inset Quotes erd
\end_inset

 like it is distributed according to 
\begin_inset Formula $\nu\circ\eta_{\theta}^{-1}$
\end_inset

, though it is generated using a path that is only governed by 
\begin_inset Formula $\tilde{\theta}$
\end_inset

.
 Now, we let
\end_layout

\begin_layout aEnumerate (ClassicThesis)
\begin_inset Formula $A_{\theta}(u)=\int_{u^{*}}^{u}\alpha_{\theta}$
\end_inset

 for suitable but otherwise arbitrary 
\begin_inset Formula $u^{*}$
\end_inset

, and
\end_layout

\begin_layout aEnumerate (ClassicThesis)
\begin_inset Formula $\nu_{i,j,\dots}$
\end_inset

 be the distribution of the 
\begin_inset Formula $(i,j,\dots)$
\end_inset

-th coordinates of 
\begin_inset Formula $\nu$
\end_inset


\end_layout

\begin_layout Standard
and use a result of 
\begin_inset CommandInset citation
LatexCommand citet
before "Lemma 2 in"
key "beskos-2006"

\end_inset

 to find the conditional expectation of the continuous log-likelihood function
 of 
\begin_inset Formula $Y_{t}^{*}(\theta,\tilde{\theta})$
\end_inset

: 
\begin_inset Formula 
\begin{eqnarray}
\mathscr{Q}(\theta\mid\tilde{\theta}) & = & \mathbb{E}_{\nu_{n}}\left[A_{\theta}(\eta_{\theta}(X_{t_{n}}))\right]-A_{\theta}(\eta_{\theta}(x_{0}))-\nonumber \\
 &  & \sum_{i=1}^{n}\mathbb{E}_{\nu_{i}}\left[\log(\sigma_{\theta}(X_{t_{i}}))\right]-\nonumber \\
 &  & \frac{1}{2}\sum_{i=1}^{n}\mathbb{E}_{\nu_{i-1,i}}\left[(\eta_{\theta}(X_{t_{i}})-\eta_{\theta}(X_{t_{i-1}}))^{2}/(t_{i}-t_{i-1})\right]-\nonumber \\
 &  & \frac{1}{2}\mathbb{E}_{\mathbb{Z}_{\tilde{\theta}}}\left[\int_{0}^{1}\left(\alpha_{\theta}^{2}+\alpha_{\theta}^{'}\right)\left(Y_{s}^{*}(\theta,\tilde{\theta})\right)ds\right].\label{eq:final-q-1}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
MCEM for the MKLDE Given Distributional Data 
\begin_inset Formula $\nu$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1] 
\end_layout

\begin_layout Plain Layout


\backslash
Function{$
\backslash
mathscr{Q}$}{$
\backslash
theta, 
\backslash
tilde{
\backslash
theta}, 
\backslash
nu, N, M$}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$
\backslash
mathscr{Q} 
\backslash
gets  $
\backslash
Call{mean}{$A_{
\backslash
theta}(
\backslash
eta_{
\backslash
theta}($
\backslash
Call{sample}{$
\backslash
nu, N$}$[,n]))$}}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$
\backslash
mathscr{Q} 
\backslash
gets 
\backslash
mathscr{Q} 
\backslash
:-
\backslash
: $
\backslash
Call{mean}{$A_{
\backslash
theta}(
\backslash
eta_{
\backslash
theta}($
\backslash
Call{sample}{$
\backslash
nu, N$}$[,1]))$}}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$
\backslash
mathscr{Q} 
\backslash
gets 
\backslash
mathscr{Q} 
\backslash
:-
\backslash
: $
\backslash
Call{sum}{
\backslash
Call{col-means}{$
\backslash
log(
\backslash
sigma_{
\backslash
theta}($
\backslash
Call{sample}{$
\backslash
nu, N$}$)$}}}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$
\backslash
mathscr{Q} 
\backslash
gets 
\backslash
mathscr{Q} 
\backslash
:-
\backslash
: $
\backslash
Call{sum}{
\backslash
Call{col-means}{
\backslash
Call{row-diffs}{$
\backslash
eta_{
\backslash
theta}($
\backslash
Call{sample}{$
\backslash
nu, N$}$)$}$^2}/$
\backslash
Call{diff}{$
\backslash
mathcal{T}$}}}
\end_layout

\begin_layout Plain Layout

	
\backslash
For{$t_i$ in $
\backslash
mathcal{T}$}
\end_layout

\begin_layout Plain Layout

		
\backslash
State{$S_i 
\backslash
gets 0, 
\backslash
Delta 
\backslash
gets t_i - t_{i-1}, 
\backslash
delta 
\backslash
gets 
\backslash
Delta / M$}
\end_layout

\begin_layout Plain Layout

		
\backslash
For{$N$ iterations}
\end_layout

\begin_layout Plain Layout

			
\backslash
State{
\backslash
textbf{sample} $t$ from $
\backslash
{0,
\backslash
delta,
\backslash
dots,M
\backslash
delta
\backslash
}$}
\end_layout

\begin_layout Plain Layout

			
\backslash
State{$
\backslash
mathbf{Z} 
\backslash
gets$ 
\backslash
Call{exact baudoin-bridge}{$
\backslash
alpha_{
\backslash
tilde{
\backslash
theta}},1,
\backslash
nu_{i-1,i} 
\backslash
circ 
\backslash
eta_{
\backslash
tilde{
\backslash
theta}}^{-1}, M, 
\backslash
Delta$}}
\end_layout

\begin_layout Plain Layout

			
\backslash
State{$Y^{*}_t 
\backslash
gets 
\backslash
mathbf{Z}_{t} + 
\backslash
Delta^{-1}((t_i - t)(H_{
\backslash
tilde{
\backslash
theta} 
\backslash
rightarrow 
\backslash
theta} (
\backslash
mathbf{Z}_0) - 
\backslash
mathbf{Z}_0) + (t-t_{i-1})(H_{
\backslash
tilde{
\backslash
theta}
\backslash
rightarrow
\backslash
theta}(
\backslash
mathbf{Z}_
\backslash
Delta) - 
\backslash
mathbf{Z}_
\backslash
Delta))$}
\end_layout

\begin_layout Plain Layout

			
\backslash
State{$S_i 
\backslash
gets S_i + (
\backslash
alpha_{
\backslash
theta}^2 + 
\backslash
alpha_{
\backslash
theta}^{'})(Y^{*}_t)/N$}
\end_layout

\begin_layout Plain Layout

		
\backslash
EndFor
\end_layout

\begin_layout Plain Layout

		
\backslash
State{$
\backslash
mathscr{Q} 
\backslash
gets Q 
\backslash
:-
\backslash
:
\backslash
frac{
\backslash
Delta}{2}S_i$} 
\end_layout

\begin_layout Plain Layout

	
\backslash
EndFor
\end_layout

\begin_layout Plain Layout

	
\backslash
State 
\backslash
Return{$
\backslash
mathscr{Q}$}
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
Function{find-mklde}{$
\backslash
theta_0, 
\backslash
nu, N, M$}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$
\backslash
tilde{
\backslash
theta} 
\backslash
gets 
\backslash
theta_0$}
\end_layout

\begin_layout Plain Layout

	
\backslash
Repeat	
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$
\backslash
tilde{
\backslash
theta} = 
\backslash
arg 
\backslash
max_{
\backslash
theta 
\backslash
in 
\backslash
Theta} 
\backslash
mathscr{Q}(
\backslash
theta, 
\backslash
tilde{
\backslash
theta}, 
\backslash
nu, N, M)$}
\end_layout

\begin_layout Plain Layout

	
\backslash
Until{convergence}
\end_layout

\begin_layout Plain Layout

	
\backslash
State 
\backslash
Return{$
\backslash
tilde{
\backslash
theta}$}
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "algo:mcem"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Note that by standard Monte Carlo integration results, we may re-write the
 last term in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:final-q-1"

\end_inset

 as 
\begin_inset Formula 
\[
\frac{1}{2}\mathbb{E}_{\mathbb{Z}_{\tilde{\theta}},U}\left[\left(\alpha_{\theta}^{2}+\alpha_{\theta}^{'}\right)\left(Y_{U}^{*}(\theta,\tilde{\theta})\right)\right]
\]

\end_inset

for some independent 
\begin_inset Formula $U\sim\mbox{Unif}[0,1]$
\end_inset

.
 
\end_layout

\begin_layout Standard
While 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:final-q-1"

\end_inset

 remains hopelessly intractable, it immediately suggests a MCEM scheme,
 assuming we have a way of sampling paths under Baudoin bridge measures.
 Suppose for the moment we do: the function 
\noun on
exact baudoin-bridge
\noun default
(
\series bold
\noun on

\begin_inset Formula $\mu,\sigma,\nu,M,\Delta$
\end_inset


\series default
\noun default
) will return discrete observations 
\begin_inset Formula $\mathbf{X}=\{\mathbf{X}_{t}\}_{t=0,\delta,\dots,M\delta}$
\end_inset

 for 
\begin_inset Formula $\delta=\Delta/M$
\end_inset

 of an Itô diffusion with drift coefficient 
\begin_inset Formula $\mu(x)$
\end_inset

 and diffusion coefficient 
\begin_inset Formula $\sigma(x)$
\end_inset

 under the Baudoin 
\begin_inset Formula $(X_{0,\Delta},\nu)$
\end_inset

-conditioning of its associated measure on 
\begin_inset Formula $[0,\Delta]$
\end_inset

, where 
\begin_inset Formula $\Delta\in(0,1]$
\end_inset

.
 Further suppose we have a function 
\noun on
sample(
\begin_inset Formula $\nu,N$
\end_inset

)
\noun default
 which returns 
\begin_inset Formula $N$
\end_inset

 samples from 
\begin_inset Formula $\nu$
\end_inset

 in a 
\begin_inset Formula $N\times n$
\end_inset

 array.
 Then, 
\begin_inset CommandInset ref
LatexCommand formatted
reference "algo:mcem"

\end_inset

 presents an MCEM algorithm which iteratively maximizes a Monte Carlo estimate
 for 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:final-q-1"

\end_inset

.
 In particular, the algorithm converges to the MKLDE, which is the 
\begin_inset Formula $\theta$
\end_inset

 that minimizes the K-L divergence of the law of 
\begin_inset Formula $X_{\mathcal{T}}$
\end_inset

 under 
\begin_inset Formula $\mathbb{Q}_{\theta}$
\end_inset

 from 
\begin_inset Formula $\nu$
\end_inset

.
 Note that we exploit the Markovian nature of the measuresin question to
 split the evaluation of the last term in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:final-q-1"

\end_inset

 into bridges on 
\begin_inset Formula $[t_{i-1},t_{i}]$
\end_inset

 for 
\begin_inset Formula $i=1,\dots,n$
\end_inset

.
 Furthermore, we simulate new samples from 
\begin_inset Formula $\nu$
\end_inset

 at every possible point in the algorithm as a simple method of Monte Carlo
 variance reduction.
\end_layout

\begin_layout Standard
One technical point we must address before continuing is the use of 
\begin_inset CommandInset ref
LatexCommand formatted
reference "algo:mcem"

\end_inset

 when only a finite number of samples from 
\begin_inset Formula $\nu$
\end_inset

 is available i.e.
 when we wish to use MCEM to find the MKLDE given the empirical law 
\begin_inset Formula $\hat{\nu}$
\end_inset

 of samples from 
\begin_inset Formula $\nu$
\end_inset

.
 We note that 
\begin_inset Formula $\hat{\nu}$
\end_inset

 is not absolutely continuous to any measure induced by a solution to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

, and thus a Baudoin 
\begin_inset Formula $(X_{\mathcal{T}},\hat{\nu})$
\end_inset

-conditioning on such a measure is not well-defined.
 However, the intuition behind such a conditioning still holds (
\begin_inset Formula $X_{\mathcal{T}}$
\end_inset

 is conditioned to follow a discrete distribution 
\begin_inset Formula $\hat{\nu}$
\end_inset

), and we will demonstrate in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "chap:5"

\end_inset

 that using 
\begin_inset Formula $\hat{\nu}$
\end_inset

 as a plug-in estimate for 
\begin_inset Formula $\nu$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "algo:mcem"

\end_inset

 produces unbiased estimates for the MKLDE given 
\begin_inset Formula $\nu$
\end_inset

.
 As such, we will gloss over the technicality of empirical distributions
 not being absolutely continuous to diffusion measures for the remainder
 of the thesis.
\end_layout

\begin_layout Standard
We have thus partially answered the question of inference on distributional
 data.
 There is, in fact, a meaningful estimate of 
\begin_inset Formula $\theta$
\end_inset

 given 
\begin_inset Formula $X_{\mathcal{T}}\sim\nu$
\end_inset

: this is precisely the value of 
\begin_inset Formula $\theta$
\end_inset

 which minimizes the K-L divergence of 
\begin_inset Formula $\mathbb{Q}_{\theta,X_{\mathcal{T}}}$
\end_inset

 from 
\begin_inset Formula $\nu$
\end_inset

 when we fix a family of potentially misspecified probability models 
\begin_inset Formula $\mathcal{Q}=\{\mathbb{Q}_{\theta}\mid\theta\in\Theta\}$
\end_inset

.
 
\begin_inset CommandInset ref
LatexCommand formatted
reference "algo:mcem"

\end_inset

 finds such a value.
 However, to implement this MCEM scheme, we must have a way to sample 
\begin_inset Formula $Y$
\end_inset

 under the Baudoin 
\begin_inset Formula $(Y_{0,\Delta},\nu\circ\eta_{\tilde{\theta}}^{-1})$
\end_inset

-conditioning of 
\begin_inset Formula $\mathbb{Y}_{\tilde{\theta}}$
\end_inset

.
 In other words, for known 
\begin_inset Formula $\tilde{\theta}$
\end_inset

, we must be able to impute the distribution of 
\begin_inset Formula $Y$
\end_inset

 on 
\begin_inset Formula $(0,\Delta)$
\end_inset

 given 
\begin_inset Formula $Y_{0,\Delta}\sim\nu\circ\eta_{\tilde{\theta}}^{-1}$
\end_inset

.
 We turn to this question in the following chapter.
\end_layout

\end_body
\end_document
