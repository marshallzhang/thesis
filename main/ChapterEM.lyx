#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass classicthesis
\begin_preamble
\usepackage{algorithm,algpseudocode}
\newref{prop}{name=Proposition~,Name=Proposition~}
\newref{prob}{name=Problem~,Name=Problem~}
\newref{thm}{name=Theorem~,Name=Theorem~}
\newref{chap}{name=Chapter~,Name=Chapter~}
\newref{part}{name=Part~,Name=Part~}
\newref{remark}{name=Remark~,Name=Remark~}
\newref{algo}{name=Algorithm~,Name=Algorithm~}
\newref{lem}{name=Lemma~,Name=Lemma~}
\MakeRobust{\Call}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
theorems-chap
\end_modules
\maintain_unincluded_children false
\language american
\language_package default
\inputencoding default
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type numerical
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Inference on Distributional Data 
\begin_inset CommandInset label
LatexCommand label
name "chap:EM"

\end_inset


\end_layout

\begin_layout Standard
In this chapter, we state and formalize the problem of inference on distribution
al data, and develop a Monte Carlo expectation-maximization algorithm to
 conduct inference on such data.
\end_layout

\begin_layout Section
Stating the Problem
\end_layout

\begin_layout Standard
We present in this section a generalization, stated informally in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "chap:Introduction"

\end_inset

, of the problem of inference on discretely observed data from diffusion
 processes.
\end_layout

\begin_layout Subsection
The Discretely Observed Data Problem
\end_layout

\begin_layout Standard
To begin, we review the discretely observed data problem.
 Inference on diffusion processes observed at discrete points in time is
 a topic of interest for many statisticians, in large part due to the prevalence
 of diffusion processes in modeling a wide range of phenomena, and the simultane
ous unavailability of continuous observations from such processes in the
 real world.
 Consider a solution to the one-dimensional stochastic differential equation
\begin_inset Formula 
\begin{equation}
dX_{t}=\mu_{\theta}(X_{t})dt+\sigma_{\theta}(X_{t})dW_{t},\label{eq:sde-with-theta}
\end{equation}

\end_inset

where 
\begin_inset Formula $\theta\in\Theta\subseteq\mathcal{R}^{k}$
\end_inset

 is an unknown parameter vector, 
\begin_inset Formula $W$
\end_inset

 is a Wiener process, and 
\begin_inset Formula $\mu_{\theta},\sigma_{\theta}$
\end_inset

 have known parametric forms up to 
\begin_inset Formula $\theta$
\end_inset

.
 Let 
\begin_inset Formula $\mathcal{X}\subseteq\mathcal{R}$
\end_inset

 be the state space of 
\begin_inset Formula $X$
\end_inset

.
 Suppose that we observe values 
\begin_inset Formula $\bar{\mathbf{x}}=\{\bar{x}_{t_{1}},\dots,\bar{x}_{t_{n}}\}\in\mathcal{X}^{n}$
\end_inset

 at a collection of times 
\begin_inset Formula $\mathcal{T}=\{t_{1}<\cdots<t_{n}=1\}$
\end_inset

 where 
\begin_inset Formula $t_{1}>0$
\end_inset

.
 Then, the log-likelihood of the data 
\begin_inset Formula $\bar{\mathbf{x}}$
\end_inset

 is 
\begin_inset Formula 
\[
\ell(\theta\mid\bar{\mathbf{x}})=\sum_{i=1}^{n}\ell_{i}(\theta),
\]

\end_inset

where 
\begin_inset Formula $\ell_{i}(\theta)=\log p_{\theta,t_{i}-t_{i-1}}(\bar{x}_{t_{i-1}},\bar{x}_{t_{i}})$
\end_inset

 and 
\begin_inset Formula $p_{\theta,t}(x,y)$
\end_inset

 is the transition density associated with 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

 as usual (we assume 
\begin_inset Formula $x_{t_{0}}=x_{0}$
\end_inset

 is fixed).
 For many specifications of 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

, 
\begin_inset Formula $p_{t}(x,y;\theta)$
\end_inset

 is not analytically tractable, and thus likelihood-based inference on discretel
y observed data has historically been understood to be quite difficult.
 In particular, maximum likelihood estimation has received significant attention
 in the literature, with proposed approaches ranging from 
\begin_inset CommandInset citation
LatexCommand citet
key "sahalia-2002"

\end_inset

's closed-form analytic likelihood approximations to the simulation-based
 strategies of 
\begin_inset CommandInset citation
LatexCommand citet
key "pedersen-1995"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand citet
key "durham-gallant-2002"

\end_inset

, and more recently, imputation-based techniques advanced by 
\begin_inset CommandInset citation
LatexCommand citet
key "beskos-2006"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citet
key "sorensen-2004"

\end_inset

 offers a comprehensive survey of the range of inferential techniques used
 for the problem of discretely observed diffusions.
\end_layout

\begin_layout Subsection
From Ex-Post to Ex-Ante
\end_layout

\begin_layout Standard
We now present the central problem of this thesis.
 We can re-interpret the discretely observed data problem by supposing we
 lived at 
\begin_inset Formula $t_{0}=0$
\end_inset

, and viewing the data 
\begin_inset Formula $\bar{\mathbf{x}}$
\end_inset

 not as observed data, but as the values that 
\begin_inset Formula $X$
\end_inset

 would take on with certainty at future times 
\begin_inset Formula $\mathcal{T}$
\end_inset

 (perhaps as prophesized by an omniscient Oracle).
 Modulo philosophical and technical subtleties, the problem has not changed
 materially: we ought to be able to conduct likelihood-based inference using
 
\begin_inset Formula $\ell(\theta\mid\bar{\mathbf{x}}),$
\end_inset

 so long as it is available, as usual.
\end_layout

\begin_layout Standard
This ex-ante perspective allows, however, for a generalization of interest
 to this thesis.
 For we may suppose that instead of knowing the values of 
\begin_inset Formula $X$
\end_inset

 at times 
\begin_inset Formula $\mathcal{T}$
\end_inset

, we know instead with certainty the joint distribution 
\begin_inset Formula $\nu$
\end_inset

 of these values.
 Intuitively, knowing 
\begin_inset Formula $\nu$
\end_inset

 ought to reveal information that we may use to learn about the parameters
 governing the dynamics of 
\begin_inset Formula $X$
\end_inset

; on the other hand, the likelihood function is no longer well-defined,
 and how to proceed with likelihood-based inference is therefore unclear.
 We refer to 
\begin_inset Formula $\nu$
\end_inset

 as distributional data, in juxtaposition to the observed data is that given
 in the context of MLE.
\end_layout

\begin_layout Standard
The problems of inference on discretely observed data and on distributional
 data are visualized in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:mle-intuition"

\end_inset

.
 The fixed data depicted on the left intuitively should help us learn about
 the dynamics of 
\begin_inset Formula $X$
\end_inset

 through MLE (for instance, it looks as if it contains some information
 about the drift of 
\begin_inset Formula $X$
\end_inset

).
 The distributional data on the right, then, with marginals centered at
 the fixed data, should contain at least as much information about the dynamics
 of 
\begin_inset Formula $X$
\end_inset

, if not more.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename /Users/marshall/Documents/senior/thesis/figures/mle_vs_gen_ed.pdf
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:mle-intuition"

\end_inset

A visualization of the generalization of MLE on discretely observed data
 proposed in this thesis.
 The value of the process of interest at 
\begin_inset Formula $t_{0}$
\end_inset

 is fixed and indicated by a black dot on the value axis.
 The left graphic depicts a fixed set of data 
\begin_inset Formula $\bar{\mathbf{x}}$
\end_inset

 over time, on which MLE can be performed if the log-likelihood is available.
 The right graphic depicts the marginal distributions of a set of distributional
 data, where the marginal distributions are centered at 
\begin_inset Formula $\bar{\mathbf{x}}$
\end_inset

.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the remainder of this chapter, we will consider the family of distributions
 
\begin_inset Formula $\mathscr{\mathcal{Q}}=\{\mathbb{Q}_{\theta}:\theta\in\Theta\}$
\end_inset

 induced by solutions to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

 with initial condition 
\begin_inset Formula $X_{0}=x_{0}$
\end_inset

 for some fixed 
\begin_inset Formula $x_{0}$
\end_inset

.
 We let 
\begin_inset Formula $\mathbb{Q}_{\theta,X_{\mathcal{T}}}$
\end_inset

 be the law of 
\begin_inset Formula $X_{\mathcal{T}}$
\end_inset

 under 
\begin_inset Formula $\mathbb{Q}_{\theta}$
\end_inset

 with density 
\begin_inset Formula $Q_{\theta,\mathcal{T}}$
\end_inset

.
 Furthermore, we let 
\begin_inset Formula $\nu$
\end_inset

 be an 
\begin_inset Formula $n$
\end_inset

-dimensional distribution on the usual probability space restricted to times
 
\begin_inset Formula $\mathcal{T}$
\end_inset

, which is absolutely continuous to 
\begin_inset Formula $\mathbb{Q}_{\theta,X_{\mathcal{T}}}$
\end_inset

 for all 
\begin_inset Formula $\theta\in\Theta$
\end_inset

.
 Then, the problem of inference on distributional data can loosely be stated
 as follows: What, if anything, can we say about 
\begin_inset Formula $\theta$
\end_inset

, given 
\begin_inset Formula $X_{\mathcal{T}}\sim\nu$
\end_inset

?
\end_layout

\begin_layout Subsection
Characterizing an Estimator
\end_layout

\begin_layout Standard
In this subsection, we propose an estimator for 
\begin_inset Formula $\theta$
\end_inset

 given 
\begin_inset Formula $X_{\mathcal{T}}\sim\nu$
\end_inset

, and make some remarks characterizing its relationship to the maximum-likelihoo
d estimator given discretely observed data.
\end_layout

\begin_layout Standard
We first note that the problem of discretely observed data can be understood
 as a limiting case of the problem of distributional data.
 In particular, we can fix some data 
\begin_inset Formula $\bar{\mathbf{x}}\in\mathcal{X}^{n}$
\end_inset

.
 Then, intuitively, if 
\begin_inset Formula $\nu^{(m)}$
\end_inset

 is a sequence of probability measures which are absolutely continuous to
 
\begin_inset Formula $\mathbb{Q}_{\theta,X_{\mathcal{T}}}$
\end_inset

 and which converge (in some sense) to the Dirac delta measure 
\begin_inset Formula $\delta_{\bar{\mathbf{x}}}$
\end_inset

, any estimator for 
\begin_inset Formula $\theta$
\end_inset

 given 
\begin_inset Formula $X_{\mathcal{T}}\sim\nu^{(m)}$
\end_inset

 should coincide with the MLE given 
\begin_inset Formula $\bar{\mathbf{x}}$
\end_inset

 as 
\begin_inset Formula $m\rightarrow\infty$
\end_inset

.
 One estimator for 
\begin_inset Formula $\theta$
\end_inset

 that seems like it ought to satisfy this criterion is 
\begin_inset Formula 
\begin{equation}
\hat{\theta}=\arg\max_{\theta\in\Theta}\int\log Q_{\theta,\mathcal{T}}(\mathbf{x})\nu(d\mathbf{x}).\label{eq:mklde}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
We define 
\begin_inset Formula $\Lambda_{\theta}(\nu)\coloneqq\int\log Q_{\theta,\mathcal{T}}(\mathbf{x})\nu(d\mathbf{x})$
\end_inset

, alluding with our notation to the traditional log-likelihood function
 
\begin_inset Formula $\ell_{\theta}(\bar{\mathbf{x}})$
\end_inset

.
 As 
\begin_inset CommandInset citation
LatexCommand citet
before "Section 1 in"
key "akaike-1973"

\end_inset

 notes, maximizing 
\begin_inset Formula $\Lambda_{\theta}(\nu)$
\end_inset

 is equivalent to minimizing the Kullback-Liebler divergence of 
\begin_inset Formula $\mathbb{Q}_{\theta,X_{\mathcal{T}}}$
\end_inset

 from 
\begin_inset Formula $\nu$
\end_inset

.
 To see this, simply write 
\begin_inset Formula 
\begin{eqnarray*}
D(\nu\:||\:\mathbb{Q}_{\theta,X_{\mathcal{T}}}) & = & \mathbb{E}_{\nu}\left[\log\frac{d\nu}{d\mathbb{Q}_{\theta,X_{\mathcal{T}}}}\right]\\
 & = & \mathbb{E}_{\nu}\left[\log\frac{d\nu}{dx}\right]-\mathbb{E}_{\nu}\left[\log\frac{d\mathbb{Q}_{\theta,X_{\mathcal{T}}}}{dx}\right].
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
For this reason, we call the proposed estimator in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:mklde"

\end_inset

 the minimum Kullback-Liebler divergence estimator (MKLDE).
 Note that this estimator, unlike traditional estimators which are functions
 of observed data, is a functional of the distribution 
\begin_inset Formula $\nu$
\end_inset

.
 We now present two remarks, which
\end_layout

\begin_layout aEnumerate (ClassicThesis)
characterize the MKLDE as a limiting case of traditional maximum likelihood
 estimation under model misspecification, and
\end_layout

\begin_layout aEnumerate (ClassicThesis)
show that the MKLDE given a particular approximation to 
\begin_inset Formula $\nu$
\end_inset

 asymptotically converges to the MKLDE given 
\begin_inset Formula $\nu$
\end_inset

.
\end_layout

\begin_layout Standard
The first remark connects MKLDE to MLE under model misspecification.
\end_layout

\begin_layout Remark
\begin_inset CommandInset label
LatexCommand label
name "rem:misspecification"

\end_inset

The MLE given discretely observed data at times 
\begin_inset Formula $\mathcal{T}$
\end_inset

 under model misspecification converges in probability to the MKLDE as the
 sample size grows.
 For consider 
\begin_inset Formula $X_{\mathcal{T}}^{(1)},\dots,X_{\mathcal{T}}^{(N)}$
\end_inset

, 
\begin_inset Formula $N$
\end_inset

 i.i.d.
 draws from 
\begin_inset Formula $\nu$
\end_inset

.
 By a result of 
\begin_inset CommandInset citation
LatexCommand citet
before "Theorem 2.2 in"
key "white-1982"

\end_inset

, 
\begin_inset Formula 
\[
\arg\max_{\theta\in\Theta}\frac{1}{N}\sum_{i=1}^{N}\log Q_{\theta,\mathcal{T}}(X_{\mathcal{T}}^{(i)})\xrightarrow{p}\arg\min_{\theta\in\Theta}\mathbb{E}_{\nu}\left[\log\frac{d\nu}{d\mathbb{Q}_{\theta,X_{\mathcal{T}}}}\right]
\]

\end_inset

as 
\begin_inset Formula $N\rightarrow\infty$
\end_inset

, and thus by the observation of 
\begin_inset CommandInset citation
LatexCommand citet
key "akaike-1973"

\end_inset

, 
\begin_inset Formula 
\[
\arg\max_{\theta\in\Theta}\frac{1}{N}\sum_{i=1}^{N}\log Q_{\theta,\mathcal{T}}(X_{\mathcal{T}}^{(i)})\xrightarrow{p}\arg\max_{\theta\in\Theta}\Lambda_{\theta}(\nu).
\]

\end_inset


\end_layout

\begin_layout Standard
The intuition for this relationship is as follows.
 Recall that a time-homogenous Markov measure is uniquely determined by
 a transition kernel and a marginal measure; an SDE satisfying the requirements
 outlined in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "chap:2"

\end_inset

 along with the initial condition 
\begin_inset Formula $X_{0}=x_{0}$
\end_inset

 therefore admits a bijection between 
\begin_inset Formula $\Theta$
\end_inset

 and 
\begin_inset Formula $\mathcal{Q}$
\end_inset

.
 In particular, the elements of 
\begin_inset Formula $\mathcal{Q}$
\end_inset

 are the only possible measures that any solution to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

 with initial condition 
\begin_inset Formula $X_{0}=x_{0}$
\end_inset

 could induce.
 Now suppose we know 
\begin_inset Formula $X_{\mathcal{T}}\sim\nu$
\end_inset

 (or, following 
\begin_inset CommandInset ref
LatexCommand formatted
reference "rem:misspecification"

\end_inset

, suppose we had infinite samples from 
\begin_inset Formula $\nu$
\end_inset

, since the empirical law of samples from 
\begin_inset Formula $\nu$
\end_inset

 converges to 
\begin_inset Formula $\nu$
\end_inset

 pointwise almost surely).
 If 
\begin_inset Formula $\nu\not\in\{\mathbb{Q}_{\mathcal{T}}:\mathbb{Q}\in\mathcal{Q}\}$
\end_inset

, it must be the case that we have misspecified our probability model.
 In this case, the best we can do is to find the value of 
\begin_inset Formula $\theta$
\end_inset

 that minimizes the K-L divergence of 
\begin_inset Formula $\mathbb{Q}_{\theta}$
\end_inset

 at 
\begin_inset Formula $\mathcal{T}$
\end_inset

 from 
\begin_inset Formula $\nu$
\end_inset

, which is precisely the MKLDE.
\end_layout

\begin_layout Standard
Having an understanding of the MKLDE as a limit in terms of sample size
 is useful because in the real world, few probabilistic forecasts offer
 a functional form for 
\begin_inset Formula $\nu$
\end_inset

.
 More often than not, we will only have access to a finite number of draws
 from 
\begin_inset Formula $\nu$
\end_inset

 (think, for example, of a group of forecasters giving forecasts for the
 value of some future variable), and we now remark on the consistency of
 the MKLDE when perfect access to 
\begin_inset Formula $\nu$
\end_inset

 is not available.
\end_layout

\begin_layout Remark
\begin_inset CommandInset label
LatexCommand label
name "rem:bootstrap"

\end_inset

Let 
\begin_inset Formula $\hat{\nu}^{(N)}$
\end_inset

 is the empirical distribution function induced by 
\begin_inset Formula $N$
\end_inset

 draws from 
\begin_inset Formula $\nu$
\end_inset

.
 Then, the MKLDE given 
\begin_inset Formula $\hat{\nu}^{(N)}$
\end_inset

 converges in probability to the MKLDE given 
\begin_inset Formula $\nu$
\end_inset

 as 
\begin_inset Formula $N\rightarrow\infty$
\end_inset

.
 For consider 
\begin_inset Formula $X_{\mathcal{T}}^{(N,1)},\dots,X_{\mathcal{T}}^{(N,N)}$
\end_inset

 drawn from 
\begin_inset Formula $\hat{\nu}^{(N)}$
\end_inset

.
 By standard results demonstrating the consistency of plug-in bootstrap
 estimators (see 
\begin_inset CommandInset citation
LatexCommand citet
key "horowitz-2002"

\end_inset

), 
\begin_inset Formula 
\begin{eqnarray*}
\int\log P_{\theta,\mathcal{T}}(\mathbf{x})\hat{\nu}^{(N)}(d\mathbf{x}) & = & \frac{1}{N}\sum_{i=1}^{N}\log Q_{\theta,\mathcal{T}}(X_{\mathcal{T}}^{(N,i)})\\
 & \xrightarrow{p} & \Lambda_{\theta}(\nu)
\end{eqnarray*}

\end_inset

and by a loose application of the 
\begin_inset Formula $\arg\max$
\end_inset

 continuous mapping theorem (see 
\begin_inset CommandInset citation
LatexCommand citet
key "kim-pollard-1990"

\end_inset

), the MKLDE given 
\begin_inset Formula $\hat{\nu}^{(N)}$
\end_inset

 is asymptotically consistent for the MKLDE given 
\begin_inset Formula $\nu$
\end_inset

 as 
\begin_inset Formula $N\rightarrow\infty$
\end_inset

.
\end_layout

\begin_layout Standard
This remark is important in that it says we do not need perfect access to
 
\begin_inset Formula $\nu$
\end_inset

 to carry out inference on 
\begin_inset Formula $\theta$
\end_inset

; rather, and luckily for this thesis, the MKLDE from bootstrapping an approxima
tion to 
\begin_inset Formula $\nu$
\end_inset

 diverges from the MKLDE given 
\begin_inset Formula $\nu$
\end_inset

 with probability zero asymptotically.
 In other words, though we can only ever draw finitely many samples from
 
\begin_inset Formula $\nu$
\end_inset

 in the real world, the simulation-based inference techniques to be presented
 below can still offer consistent (though perhaps less efficient) estimates
 of 
\begin_inset Formula $\theta$
\end_inset

 by taking 
\begin_inset Formula $\hat{\nu}$
\end_inset

 as a plug-in for 
\begin_inset Formula $\nu$
\end_inset

.
 
\begin_inset Formula $\Lambda_{\theta}(\hat{\nu})$
\end_inset

 is this scenario is therefore a function of fixed data, since 
\begin_inset Formula $\hat{\nu}$
\end_inset

 is constructed from a set of observations drawn from 
\begin_inset Formula $\nu$
\end_inset

; as such, the MKLDE can be understood as a traditional estimator when we
 only have finitely many samples from 
\begin_inset Formula $\nu$
\end_inset

.
\end_layout

\begin_layout Standard
These remarks together give an account of why the estimator defined in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:mklde"

\end_inset

 is a statistically meaningful and useful estimator for 
\begin_inset Formula $\theta$
\end_inset

 in the context of distributional data.
 In particular, suppose 
\begin_inset Formula $\mathbb{P}$
\end_inset

 is a true but unknown probability model, but the law of 
\begin_inset Formula $X_{\mathcal{T}}$
\end_inset

 under 
\begin_inset Formula $\mathbb{P}$
\end_inset

 is known to be 
\begin_inset Formula $\nu$
\end_inset

.
 Then, the MKDLE given 
\begin_inset Formula $\nu$
\end_inset

 over a parameterized family of probability models 
\begin_inset Formula $\mathcal{Q}$
\end_inset

 identifies the 
\begin_inset Formula $\mathbb{Q}\in\mathcal{Q}$
\end_inset

 which, when restricted to 
\begin_inset Formula $\mathcal{T}$
\end_inset

, has the minimum K-L divergence from 
\begin_inset Formula $\nu$
\end_inset

.
 The MKLDE is furthermore asymptotically consistent for approximations 
\begin_inset Formula $\hat{\nu}$
\end_inset

 to 
\begin_inset Formula $\nu$
\end_inset

.
 However, given the unavailability of a transition density for most diffusion
 processes, it quickly becomes clear that 
\begin_inset Formula $\Lambda_{\nu}(\theta)$
\end_inset

 has no obvious functional form for all but the most specific choices of
 
\begin_inset Formula $\mu_{\theta},\sigma_{\theta}$
\end_inset

, and 
\begin_inset Formula $\nu$
\end_inset

.
 Solving for the MKLDE is therefore impossible in general from an analytic
 standpoint; as such, the next section will develop a simulation-based strategy
 for finding the MKLDE.
\end_layout

\begin_layout Section
Simulation-Based K-L Divergence Minimization
\end_layout

\begin_layout Standard
One solution in the literature to the problem of likelihood-based inference
 for discretely observed diffusions is the use of simulation-based inference
 techniques.
 This approach began with the seminal paper of 
\begin_inset CommandInset citation
LatexCommand citet
key "pedersen-1995"

\end_inset

.
 The key insight is that were the continuous path of the data available,
 the likelihood function would be given by Girsanov's formula; however,
 with only discrete observations, the likelihood function is in general
 intractable.
 This framing of the problem suggests that it can be considered a problem
 of missing data, and 
\begin_inset CommandInset citation
LatexCommand citet
key "roberts-stramer-2001,elerian-chib-shephard-2001"

\end_inset

, and others simultaneously realized that simulation of diffusion bridges
 could be leveraged to supply such data.
 A method of particular interest is that of 
\begin_inset CommandInset citation
LatexCommand citet
key "beskos-2006"

\end_inset

, where an Monte Carlo expectation-maximization (MCEM) algorithm following
 
\begin_inset CommandInset citation
LatexCommand citet
key "dempster-1977"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand citet
key "wei-tanner-1990"

\end_inset

 is proposed, using the Exact Algorithm for the simulation of diffusion
 bridges developed in 
\begin_inset CommandInset citation
LatexCommand citet
key "beskos-roberts-2005"

\end_inset

.
\end_layout

\begin_layout Standard
We generalize the results of 
\begin_inset CommandInset citation
LatexCommand citet
key "roberts-stramer-2001,beskos-2006,bladt-sorensen-2014"

\end_inset

 to propose a simulation-based method to find the MKLDE.
 As noted above, even writing out 
\begin_inset Formula $\Lambda_{\nu}(\theta)$
\end_inset

, let alone maximizing it analytically, is impossible in general.
 However, noting the close parallels between MLE on discretely observed
 data and MKLDE on distributional data, we develop in this section a Monte
 Carlo expectation-maximization algorithm which converges to the MKLDE.
\end_layout

\begin_layout Subsection
The Case of Unit Diffusion Coefficient
\end_layout

\begin_layout Standard
We will first consider the highly specific case of 
\begin_inset Formula $\sigma(x;\theta)$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

 being equal to unity so that we may focus deriving the general shape of
 a simulation strategy.
 In particular, in this subsection, we will derive an EM algorithm that
 maximizes 
\begin_inset Formula $\Lambda_{\theta}(\nu)$
\end_inset

, in a manner analagous to the EM algorithm of 
\begin_inset CommandInset citation
LatexCommand citet
key "beskos-2006"

\end_inset

 which maximizes 
\begin_inset Formula $\ell_{\theta}(\bar{\mathbf{x}})$
\end_inset

 for discretely observed data 
\begin_inset Formula $\bar{\mathbf{x}}\in\mathcal{X}^{n}$
\end_inset

.
 We first prove the central result of this chapter, which will allow us
 to derive such an algorithm, recalling that the likelihood of a continuous
 path of a solution to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

 where 
\begin_inset Formula $\sigma(x;\theta)=1$
\end_inset

 is readily available by Girsanov's theorem.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:em"

\end_inset

Fix an parameter estimate 
\begin_inset Formula $\tilde{\theta}\in\Theta$
\end_inset

 and distribution 
\begin_inset Formula $\nu$
\end_inset

 satisfying the usual requirements.
 Then, 
\begin_inset Formula 
\begin{equation}
\arg\max_{\theta\in\Theta}\Lambda_{\theta}(\nu)-\Lambda_{\tilde{\theta}}(\nu)=\arg\max_{\theta\in\Theta}\mathbb{E}_{\mathbb{Q}_{\tilde{\theta}}^{\nu}}\left[\log Q_{\theta}(X)\right],\label{eq:em-equation}
\end{equation}

\end_inset

where 
\begin_inset Formula $\mathbb{Q}_{\tilde{\theta}}^{\nu}$
\end_inset

 is the Baudoin 
\begin_inset Formula $(X_{\mathcal{T}},\nu)$
\end_inset

-conditioning of the measure induced by a solution to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

 governed by parameter 
\begin_inset Formula $\tilde{\theta}$
\end_inset

 with initial condition 
\begin_inset Formula $X_{0}=x_{0}$
\end_inset

, and 
\begin_inset Formula $X$
\end_inset

 is a random path distributed according to 
\begin_inset Formula $\mathbb{Q}_{\tilde{\theta}}^{\nu}$
\end_inset

.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $X$
\end_inset

 be a solution to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

 with constant initial condition as usual.
 We begin by re-expressing the objective function on the left hand side
 of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:em-equation"

\end_inset

 as 
\begin_inset Formula 
\begin{eqnarray}
\Lambda_{\theta}(\nu)-\Lambda_{\tilde{\theta}}(\nu) & = & \int\log P_{\theta,\mathcal{T}}(\mathbf{x})\nu(d\mathbf{x})-\Lambda_{\tilde{\theta}}(\nu)\nonumber \\
 & = & \int\log\int P_{\theta,\mathcal{T}}(\mathbf{x}\mid z)P_{\theta,\mathcal{T}^{c}}(z)dz\nu(d\mathbf{x})-\Lambda_{\tilde{\theta}}(\nu),\label{eq:firststepem}
\end{eqnarray}

\end_inset

where we take
\series bold
 
\begin_inset Formula $Z$
\end_inset

 
\series default
to be missing data representing the path of 
\begin_inset Formula $X$
\end_inset

 on 
\begin_inset Formula $t\in[0,1]$
\end_inset

.
 Then, following standard arguments in the derivation of EM algorithms (see
 
\begin_inset CommandInset citation
LatexCommand citet
key "borman-2006"

\end_inset

), we can find from 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:firststepem"

\end_inset

 that
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
\Lambda_{\theta}(\nu)-\Lambda_{\tilde{\theta}}(\nu) & \geq\iint\log\left(\frac{P_{\theta}(\mathbf{x},z)}{P_{\tilde{\theta},\mathcal{T}^{c}}(z\mid\mathbf{x})}\right)P_{\tilde{\theta},\mathcal{T}^{c}}(z\mid\mathbf{x})dz\nu(d\mathbf{x})-\Lambda_{\tilde{\theta}}(\nu)\nonumber \\
 & =\iint\log\left(\frac{P_{\theta}(\mathbf{x},z)}{P_{\tilde{\theta}}(z\mid\mathbf{x})P_{\tilde{\theta}}(\mathbf{x})}\right)\mathbb{P}_{\tilde{\theta}}(dz\mid\mathbf{x})\nu(d\mathbf{x}).\label{eq:Deltatn}
\end{align}

\end_inset


\begin_inset Formula 
\[
\iint\log\left(\frac{P_{\theta}(z)}{P_{\tilde{\theta}}(z)}\right)P_{\tilde{\theta}}(z\mid\mathbf{x})\nu(\mathbf{x})=\int\log\left(\frac{P_{\theta}(z)}{P_{\tilde{\theta}}(z)}\right)\mathbb{P}_{\tilde{\theta}}^{\nu}(dz)
\]

\end_inset


\end_layout

\begin_layout Proof
Assuming suitable regularity conditions, note that 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Deltatn"

\end_inset

 can be re-written as 
\begin_inset Formula 
\[
\Delta(\theta\mid\tilde{\theta})\coloneqq\int\log\left(\frac{P_{\theta}(z)}{P_{\tilde{\theta}}(z)}\right)\mathbb{P}_{\tilde{\theta}}^{\nu}(dz)
\]

\end_inset

by the definition of a Baudoin conditioning.
 Now, let 
\begin_inset Formula $Q(\theta\mid\tilde{\theta})\coloneqq\Lambda^{\nu}(\tilde{\theta})+\Delta(\theta\mid\tilde{\theta})\leq\Lambda^{\nu}(\theta)$
\end_inset

.
 Once again, by standard arguments, any 
\begin_inset Formula $\theta$
\end_inset

 that increases 
\begin_inset Formula $Q(\theta\mid\tilde{\theta})$
\end_inset

 must also increase 
\begin_inset Formula $\Lambda^{\nu}(\theta)$
\end_inset

.
 To maximize this increase, it suffices to solve for
\begin_inset Formula 
\[
\arg\max_{\theta\in\Theta}Q(\theta\mid\tilde{\theta})=\arg\max_{\theta\in\Theta}\mathbb{E}_{\mathbb{P}_{\tilde{\theta}}^{\nu}}\left[\log P_{\theta}(X)\right],
\]

\end_inset

and the theorem follows as desired.
\end_layout

\begin_layout Standard
Note that when 
\begin_inset Formula $\nu=\delta_{\bar{\mathbf{x}}}$
\end_inset

 (in some limiting sense) for fixed data 
\begin_inset Formula $\bar{\mathbf{x}}$
\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:em-equation"

\end_inset

 reduces to 
\begin_inset Formula 
\[
\arg\max_{\theta\in\Theta}\ell(\theta\mid\bar{\mathbf{x}})-\ell(\tilde{\theta}\mid\bar{\mathbf{x}})=\arg\max_{\theta}\mathbb{E}_{Z\mid\bar{\mathbf{x}},\tilde{\theta}}\left[\log P_{\theta}(Z,\bar{\mathbf{x}})\right]
\]

\end_inset

where the expectation is taken over diffusion bridges 
\begin_inset Formula $Z$
\end_inset

.
 This equation underlies the EM algorithm of 
\begin_inset CommandInset citation
LatexCommand citet
before "Eq. 24 in"
key "beskos-2006"

\end_inset

 for the case of discretely observed data.
 
\end_layout

\begin_layout Standard
By Girsanov's theorem, we know that the complete-data log-likelihood is
 
\begin_inset Formula 
\[
\log Q_{\theta}(X)=\int_{0}^{1}\mu_{\theta}(X_{s})dx_{s}-\frac{1}{2}\int_{0}^{1}\mu_{\theta}^{2}(X_{s})ds,
\]

\end_inset

and thus the expectation step of an EM algorithm derived from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:em"

\end_inset

 would consist of computing
\begin_inset Formula 
\begin{equation}
Q(\theta\mid\tilde{\theta})=\mathbb{E}_{\mathbb{Q}_{\tilde{\theta}}^{\nu}}\left[\int_{0}^{1}\mu_{\theta}(X_{s})dX_{s}-\frac{1}{2}\int_{0}^{1}\mu_{\theta}^{2}(X_{s})ds\right].\label{eq:simple-q}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Though 
\begin_inset Formula $Q$
\end_inset

 is still intractable, it is suggestive of a Monte Carlo implementation
 of the EM algorithm following 
\begin_inset CommandInset citation
LatexCommand citet
key "wei-tanner-1990"

\end_inset

 if only we could sample from 
\begin_inset Formula $\mathbb{Q}_{\tilde{\theta}}^{\nu}$
\end_inset

.
 But before developing such an implementation, we generalize 
\begin_inset Formula $Q$
\end_inset

 for the case of diffusion coefficient known only up to 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Subsection
Augmentation Under the Lamperti Transform
\end_layout

\begin_layout Standard
The restriction of the diffusion coefficient to unity makes the 
\begin_inset Formula $Q$
\end_inset

 function presented above almost useless for practical purposes.
 In this section, we relax this assumption and derive an EM algorithm suitable
 for general use.
 Our general strategy is to first transform a diffusion with general diffusion
 coefficient to one with unit diffusion coefficient.
 Then, we derive the continuous log-likelihood of such a transformed process,
 and plug this likelihood into 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:em-equation"

\end_inset

.
\end_layout

\begin_layout Standard
Recall that for any solution to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sde-with-theta"

\end_inset

, we may define the Lamperti transform 
\begin_inset Formula $\eta_{\theta}(x)$
\end_inset

, where 
\begin_inset Formula 
\begin{equation}
\eta_{\theta}(x)=\int_{x^{*}}^{x}\frac{1}{\sigma_{\theta}(y)}dy,\label{eq:lamperti}
\end{equation}

\end_inset

for appropriate but otherwise arbitrary 
\begin_inset Formula $x^{*}$
\end_inset

.
 If we set 
\begin_inset Formula $Y_{t}(\theta)=\eta_{\theta}(X_{t})$
\end_inset

, by Ito's lemma, 
\begin_inset Formula $Y$
\end_inset

 is the solution to the stochastic differential equation
\begin_inset Formula 
\begin{equation}
dY_{t}=\alpha_{\theta}(Y_{t})dt+dW_{t},\label{eq:eta-y}
\end{equation}

\end_inset

where 
\begin_inset Formula 
\[
\alpha_{\theta}(y)=\frac{\mu_{\theta}(\eta_{\theta}^{-1}(y))}{\sigma_{\theta}(\eta_{\theta}^{-1}(y))}-\frac{1}{2}\sigma_{\theta}^{'}(\eta_{\theta}^{-1}(y)).
\]

\end_inset

The Lamperti transform is therefore a continuous transformation that reduces
 the diffusion coefficient of any SDE to unity; in conjunction with the
 change of variables formula, it seems like a trivial task to adapt 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:simple-q"

\end_inset

 for general diffusions.
\end_layout

\begin_layout Standard
However, 
\begin_inset CommandInset citation
LatexCommand citet
key "bladt-sorensen-2014"

\end_inset

 point out that the issue with the Lamperti transform is that the distribution
 of 
\begin_inset Formula $Y$
\end_inset

 at times 
\begin_inset Formula $\mathcal{T}$
\end_inset

 is now dependent on the parameter 
\begin_inset Formula $\theta$
\end_inset

, while the EM algorithm requires that the given data remain fixed.
 We adapt their proposed solution to our problem, referring the reader to
 
\begin_inset CommandInset citation
LatexCommand citet
before "p. 25 in"
key "bladt-sorensen-2014"

\end_inset

 for details of their implementation.
 For each 
\begin_inset Formula $i=1,\dots,n$
\end_inset

 we consider 
\begin_inset Formula $t_{i-1}\leq t\leq t_{i}$
\end_inset

.
 Let 
\begin_inset Formula $X$
\end_inset

 be a path under 
\begin_inset Formula $\mathbb{Q}_{\tilde{\theta}}^{\nu}$
\end_inset

 and let 
\begin_inset Formula $Z(\tilde{\theta})=\eta_{\tilde{\theta}}(X)$
\end_inset

.
 Setting 
\begin_inset Formula $H_{\tilde{\theta}\rightarrow\theta}=\eta_{\theta}\circ\eta_{\tilde{\theta}}^{-1}$
\end_inset

, we define 
\begin_inset Formula 
\begin{eqnarray*}
Y_{t}^{*}(\theta,\tilde{\theta}) & = & Z_{t}(\tilde{\theta})+\frac{(t_{i}-t)(H_{\tilde{\theta}\rightarrow\theta}(Z_{t_{i-1}}(\tilde{\theta}))-Z_{t_{i-1}}(\tilde{\theta}))}{t_{i}-t_{i-1}}+\\
 &  & \frac{(t-t_{i-1})(H_{\tilde{\theta}\rightarrow\theta}(Z_{t_{i}}(\tilde{\theta}))-Z_{t_{i}}(\tilde{\theta}))}{t_{i}-t_{i-1}}.
\end{eqnarray*}

\end_inset

Note that 
\begin_inset Formula $Y_{t_{i-1}}^{*}(\theta,\tilde{\theta})=H_{\tilde{\theta}\rightarrow\theta}(Z_{t_{i-1}}(\tilde{\theta}))$
\end_inset

 and 
\begin_inset Formula $Y_{t_{i}}^{*}(\theta,\tilde{\theta})=H_{\tilde{\theta}\rightarrow\theta}(Z_{t_{i}}(\tilde{\theta}))$
\end_inset

.
 Then, letting 
\begin_inset Formula $A_{\theta}(u)=\int_{u^{*}}^{u}\alpha_{\theta}$
\end_inset

 for suitable but otherwise arbitrary 
\begin_inset Formula $u^{*}$
\end_inset

, we follow 
\begin_inset CommandInset citation
LatexCommand citet
before "Lemma 2 in"
key "beskos-2006"

\end_inset

 to find the conditional expectation of the relevant continuous log-likelihood
 function of 
\begin_inset Formula $Y_{t}^{*}(\theta,\tilde{\theta})$
\end_inset

, 
\begin_inset Formula 
\begin{eqnarray}
Q(\theta\mid\tilde{\theta}) & = & \mathbb{E}_{\mathbb{Q}_{\tilde{\theta}}^{\nu}}\left[A_{\theta}(Z_{t_{n}}(\theta))\right]-A_{\theta}(\eta_{\theta}(x_{0}))-\nonumber \\
 &  & \sum_{i=1}^{n}\mathbb{E}_{\mathbb{Q}_{\tilde{\theta}}^{\nu}}\left[\log(\sigma_{\theta}(X_{t_{i}}))\right]-\nonumber \\
 &  & \frac{1}{2}\sum_{i=1}^{n}\mathbb{E}_{\mathbb{Q}_{\tilde{\theta}}^{\nu}}\left[(Z_{t_{i}}(\theta)-Z_{t_{i-1}}(\theta))^{2}/(t_{i}-t_{i-1})\right]-\nonumber \\
 &  & \frac{1}{2}\sum_{i=1}^{n}\mathbb{E}_{\mathbb{Q}_{\tilde{\theta}}^{\nu}}\left[\int_{t_{i-1}}^{t_{i}}\left(\alpha_{\theta}^{2}+\alpha_{\theta}^{'}\right)\left(Y_{t}^{*}(\theta,\tilde{\theta})\right)dt\right],\label{eq:final-q}
\end{eqnarray}

\end_inset

recalling that 
\begin_inset Formula $X_{t_{0}}=x_{0}$
\end_inset

 is fixed.
 By writing the expectation with respect to 
\begin_inset Formula $\mathbb{Q}_{\tilde{\theta}}^{\nu}$
\end_inset

, we keep the given distributional data fixed, which allows the EM algorithm
 to converge properly.
 Now, setting
\end_layout

\begin_layout aEnumerate (ClassicThesis)
\begin_inset Formula $\nu_{i,j,\dots}$
\end_inset

 to be the distribution of the 
\begin_inset Formula $(i,j,\dots)$
\end_inset

-th coordinates of 
\begin_inset Formula $\nu$
\end_inset

, and
\end_layout

\begin_layout aEnumerate (ClassicThesis)
\begin_inset Formula $U_{i}$
\end_inset

 to be an independent Uniform random variable on 
\begin_inset Formula $[t_{i-1},t_{i}]$
\end_inset

,
\end_layout

\begin_layout Standard
we note that we can equivalently write 
\begin_inset Formula 
\begin{eqnarray}
Q(\theta\mid\tilde{\theta}) & = & \mathbb{E}_{\nu_{n}}\left[A_{\theta}(\eta_{\theta}(X_{t_{n}}))\right]-A_{\theta}(\eta_{\theta}(x_{0}))-\nonumber \\
 &  & \sum_{i=1}^{n}\mathbb{E}_{\nu_{i}}\left[\log(\sigma_{\theta}(X_{t_{i}}))\right]-\nonumber \\
 &  & \frac{1}{2}\sum_{i=1}^{n}\mathbb{E}_{\nu_{i-1,i}}\left[(\eta_{\theta}(X_{t_{i}})-\eta_{\theta}(X_{t_{i-1}}))^{2}/(t_{i}-t_{i-1})\right]-\nonumber \\
 &  & \frac{1}{2}\sum_{i=1}^{n}(t_{i}-t_{i-1})\mathbb{E}_{\mathbb{Q}_{\tilde{\theta}}^{\nu},U_{i}}\left[\left(\alpha_{\theta}^{2}+\alpha_{\theta}^{'}\right)\left(Y_{U_{i}}^{*}(\theta,\tilde{\theta})\right)\right].\label{eq:final-q-1}
\end{eqnarray}

\end_inset

This follows by the fact that the expectations in all terms but last in
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:final-q"

\end_inset

 are taken only over the values of 
\begin_inset Formula $X$
\end_inset

 at times 
\begin_inset Formula $\mathcal{T}$
\end_inset

, and from standard Monte Carlo integration results.
 
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
MCEM for the MKLDE Given Distributional Data
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1] 
\end_layout

\begin_layout Plain Layout


\backslash
Function{$Q$}{$
\backslash
theta, 
\backslash
tilde{
\backslash
theta}, 
\backslash
nu, N$}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$Q 
\backslash
gets $
\backslash
Call{mean}{$A_{
\backslash
theta}(
\backslash
eta_{
\backslash
theta}($
\backslash
Call{sample}{$
\backslash
nu, N$}$[,n]))$}}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$Q 
\backslash
gets Q 
\backslash
:-
\backslash
: $
\backslash
Call{mean}{$A_{
\backslash
theta}(
\backslash
eta_{
\backslash
theta}($
\backslash
Call{sample}{$
\backslash
nu, N$}$[,1]))$}}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$Q 
\backslash
gets Q 
\backslash
:-
\backslash
: $
\backslash
Call{sum}{
\backslash
Call{column-means}{$
\backslash
log(
\backslash
sigma_{
\backslash
theta}($
\backslash
Call{sample}{$
\backslash
nu, N$}$)$}}}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{TO BE COMPLETED}
\end_layout

\begin_layout Plain Layout

	
\backslash
For{$i = 1,
\backslash
dots, N$}
\end_layout

\begin_layout Plain Layout

		
\backslash
State{$Y_
\backslash
mathcal{T}^{(i)} 
\backslash
gets 
\backslash
eta_{
\backslash
theta}(X_
\backslash
mathcal{T}^{(i)})$, where $X_
\backslash
mathcal{T}^{(i)} 
\backslash
sim 
\backslash
nu$}
\end_layout

\begin_layout Plain Layout

		
\backslash
State{$Y^{*,(i)} 
\backslash
gets$ 
\backslash
Call{exact $
\backslash
nu$-bridge}{$
\backslash
mu_{
\backslash
tilde{
\backslash
theta}}, 
\backslash
sigma_{
\backslash
tilde{
\backslash
theta}}, 
\backslash
nu 
\backslash
circ 
\backslash
eta_
\backslash
theta^{-1}, 
\backslash
mathbf{T}$}}
\end_layout

\begin_layout Plain Layout

		
\backslash
State{$U^{(i)} 
\backslash
gets$ 
\backslash
Call{sample}{$
\backslash
mathbf{T}$}}
\end_layout

\begin_layout Plain Layout

	
\backslash
EndFor
\end_layout

\begin_layout Plain Layout

	
\backslash
State 
\backslash
Return{${
\backslash
displaystyle
\backslash
frac{1}{N} 
\backslash
sum^{N}_{i=1}  [
\backslash
alpha_{
\backslash
tilde{
\backslash
theta}}(Y_1^{(i)}) - 
\backslash
alpha_{
\backslash
tilde{
\backslash
theta}}(Y_0^{(i)})] - 
\end_layout

\begin_layout Plain Layout

					 			 
\backslash
frac{1}{2N}
\backslash
sum^{N}_{i=1} (
\backslash
mu_{
\backslash
tilde{
\backslash
theta}}^2 + 
\backslash
mu_{
\backslash
tilde{
\backslash
theta}}^{'})(Y^{*,(i)}_{U^{(i)}})}$}
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
Function{find-mklde}{$
\backslash
theta_0, 
\backslash
nu, N$}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$
\backslash
tilde{
\backslash
theta} 
\backslash
gets 
\backslash
theta_0$}	
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$
\backslash
mathbf{repeat
\backslash
;} 
\backslash
tilde{
\backslash
theta} = 
\backslash
arg 
\backslash
max_{
\backslash
theta 
\backslash
in 
\backslash
Theta} Q(
\backslash
theta, 
\backslash
tilde{
\backslash
theta}, 
\backslash
nu, N)
\backslash
;$$
\backslash
mathbf{until}$ convergence}
\end_layout

\begin_layout Plain Layout

	
\backslash
State 
\backslash
Return{$
\backslash
tilde{
\backslash
theta}$}
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "algo:mcem"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
While 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:final-q-1"

\end_inset

 remains hopelessly intractable, it immediately suggests a Monte Carlo EM
 (MCEM) scheme, assuming we have a way of sampling from the Baudoin bridge
 measure 
\begin_inset Formula $\mathbb{Q}_{\theta}^{\nu}$
\end_inset

.
 Suppose for the moment we do: the function 
\noun on
exact baudoin-bridge
\noun default
(
\series bold
\noun on

\begin_inset Formula $\theta,\nu,M,\Delta$
\end_inset


\series default
\noun default
) will return discrete observations at 
\begin_inset Formula $\{0,\delta,\dots,M\delta\}$
\end_inset

 for 
\begin_inset Formula $\delta=\Delta/M$
\end_inset

 of an exact diffusion following the Baudoin 
\begin_inset Formula $(X_{0,\Delta},\nu)$
\end_inset

-conditioning of 
\begin_inset Formula $\mathbb{Q}_{[0,\Delta]}$
\end_inset

.
 We also suppose we have a function 
\noun on
sample(
\begin_inset Formula $\nu,N$
\end_inset

)
\noun default
 which returns 
\begin_inset Formula $N$
\end_inset

 samples from 
\begin_inset Formula $\nu$
\end_inset

 in a 
\begin_inset Formula $N\times n$
\end_inset

 matrix.
 Then, 
\begin_inset CommandInset ref
LatexCommand formatted
reference "algo:mcem"

\end_inset

 presents an MCEM algorithm which, given 
\begin_inset Formula $\nu$
\end_inset

, converges to the MKLDE.
 We note that there is no need to simulate an entire bridge over 
\begin_inset Formula $[0,1]$
\end_inset

 to compute the final term of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:final-q-1"

\end_inset

: due to the Markov property, for any realization of 
\begin_inset Formula $U_{i}$
\end_inset

 , we merely need to take the value at 
\begin_inset Formula $U_{i}\mbox{mod}t_{i-1}$
\end_inset

 of a Baudoin 
\begin_inset Formula $(X_{0,t_{i}-t_{i-1}},\nu_{i})$
\end_inset

-bridge simulated on 
\begin_inset Formula $[0,t_{i}-t_{i-1}]$
\end_inset

.
 We simulate new samples from 
\begin_inset Formula $\nu$
\end_inset

 at every possible point in the algorithm as a simple method of Monte Carlo
 variance reduction.
\end_layout

\begin_layout Standard
We have thus partially answered the question of inference on distributional
 data.
 There is in fact a meaningful estimate of 
\begin_inset Formula $\theta$
\end_inset

 when we are given that 
\begin_inset Formula $X_{\mathcal{T}}$
\end_inset

 is distributed according to 
\begin_inset Formula $\nu$
\end_inset

: this is precisely the value of 
\begin_inset Formula $\theta$
\end_inset

 which minimizes the K-L divergence of 
\begin_inset Formula $\mathbb{Q}_{\theta,\mathcal{T}}$
\end_inset

 from 
\begin_inset Formula $\nu$
\end_inset

, and we can find such a value using 
\begin_inset CommandInset ref
LatexCommand formatted
reference "algo:mcem"

\end_inset

.
 Moreover, by 
\begin_inset CommandInset ref
LatexCommand formatted
reference "rem:bootstrap"

\end_inset

, when we only have a finite number of sample from 
\begin_inset Formula $\nu$
\end_inset

, we may use the empirical distribution 
\begin_inset Formula $\hat{\nu}$
\end_inset

 as a plug-in estimate for 
\begin_inset Formula $\nu$
\end_inset

.
 However, to implement this MCEM scheme, we must have a way to sample from
 the Baudoin 
\begin_inset Formula $(X_{0,\Delta},\nu)$
\end_inset

-conditioning of 
\begin_inset Formula $\mathbb{Q}_{[0,\Delta]}$
\end_inset

; in other words, for known 
\begin_inset Formula $\theta$
\end_inset

, we must be able to impute the distribution of 
\begin_inset Formula $X$
\end_inset

 on 
\begin_inset Formula $(0,\Delta)$
\end_inset

 given 
\begin_inset Formula $X_{0,\Delta}\sim\nu$
\end_inset

.
 We turn to this question in the next chapter.
\end_layout

\end_body
\end_document
