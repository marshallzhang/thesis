%% LyX 2.1.4 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[american,fontsize=11pt,paper=a4,twoside,openright,titlepage,numbers=noenddot,headinclude,BCOR=5mm,footinclude=true,cleardoublepage=empty]{scrreprt}
\usepackage[T1]{fontenc}
\setcounter{secnumdepth}{2}
\usepackage{prettyref}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[numbers]{natbib}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
% Classic Thesis Style loader
\makeatother
\input{classicthesis-config.tex}
\makeatletter
% use Latin Modern instead of Computer Modern sans serif
\renewcommand{\sfdefault}{lmss}
\theoremstyle{plain}
\ifx\thechapter\undefined
\newtheorem{thm}{\protect\theoremname}
\else
\newtheorem{thm}{\protect\theoremname}[chapter]
\fi
  \theoremstyle{definition}
  \newtheorem{defn}[thm]{\protect\definitionname}
  \theoremstyle{plain}
  \newtheorem{prop}[thm]{\protect\propositionname}
  \theoremstyle{plain}
  \newtheorem{lem}[thm]{\protect\lemmaname}

\makeatother

\usepackage{babel}
  \providecommand{\definitionname}{Definition}
  \providecommand{\lemmaname}{Lemma}
  \providecommand{\propositionname}{Proposition}
\providecommand{\theoremname}{Theorem}

\begin{document}

\chapter{The Theory of Markov Bridges}

In this chapter, we consider the probability space $\left(\Omega,\mathcal{B}\left(\Omega\right),\mathcal{F},\mathbb{P}\right)$,
where the sample space $\Omega=\mathcal{C}\left(I,\mathbb{R}\right)$
is the space of real-valued continuous functions $\omega:I\rightarrow\mathbb{R}$,
which is equipped with its Borel $\sigma$-algebra. $\Omega$ be endowed
with the canonical filtration $\mathcal{F}$ generated by the canonical
process $X=\left\{ X_{t}\right\} _{t\in I}$, which for some $t\in I$,
is such that 
\[
X_{t}\left(\omega\right):=\omega\left(t\right)
\]
where $\omega\in\Omega$. Let $\mathbb{P}$ be a probability measure,
which we will call a path measure. For any subset $S\in I$, let $X_{S}=\left\{ X_{s}\right\} _{s\in S}$
be the canonical process over $S$, $\mathcal{F}_{S}=\sigma\left(\left\{ X_{s}\left(\omega\right):s\in S,\omega\in\Omega\right\} \right)$
be the $\sigma-$algebra of events observed during $S$, and $\mathbb{P}_{S}$
be the restriction of $\mathbb{P}$ to $\Omega_{S}:=\left\{ X_{s}\left(\omega\right):s\in S,\omega\in\Omega\right\} $.
Furthermore, for ease of notation, let $:t$ be the set $\left[0,t\right]$,
$t:$ be the set $\left[t,1\right]$, $t:u$ be the set $\left[t,u\right]$.

We begin our exposition of bridge measures by exploring general Markov
measures.


\section{Markov Measures}

In this section, we introduce fundamental notions related to Markov
measures. Two major results are presented in this section: the first,
demonstrating the construction of a unique Markov measure given a
marginal measure and appropriate transition kernels, and the second,
stating a criterion for when a path measure dominated by a Markov
measure is also Markov.
\begin{defn}[Markov measure and Markov process]
 A path measure $\mathbb{P}$ on $\Omega$ is said to be a Markov
measure if for any $t\in I$ and for any events $A\in\mathcal{F}_{:t}$
and $B\in\mathcal{F}_{t:}$, 
\begin{equation}
\mathbb{P}\left(A\cap B\mid X_{t}\right)=\mathbb{P}\left(A\mid X_{t}\right)\mathbb{P}\left(B\mid X_{t}\right),\mbox{ }\mathbb{P}-a.e.\label{eq:markov-prop}
\end{equation}
The canonical process under a Markov measure is a Markov process.
\end{defn}
Informally, the past and the future are conditionally independent
given the present under a Markov measure. \eqref{eq:markov-prop}
is known as the (symmetric) Markov property. Another common and useful
formulation of a Markov measure says that the canonical process is
memoryless under such a measure, a notion formalized below.
\begin{prop}[\citet{doob-1953}]
A path measure $\mathbb{P}$ satisfies the Markov property if and
only if for all $t\in I$ and all $A\in\mathcal{F}_{:t},B\in\mathcal{F}_{t:}$,
\begin{eqnarray}
\mathbb{P}\left(B\mid X_{:t}\right) & = & \mathbb{P}\left(B\mid X_{t}\right),\mbox{ }\mathbb{P}-a.e.\label{eq:memorylessness}\\
\mathbb{P}\left(A\mid X_{t:}\right) & = & \mathbb{P}\left(A\mid X_{t}\right),\mbox{ }\mathbb{P}-a.e.\label{eq:rev-memorylessness}
\end{eqnarray}

\end{prop}
Thus, not only does a Markov process forget its past, it is also memoryless
in a time-symmetric manner; in other words, a Markov process remains
Markovian under time-reversal. We define now the transition kernels
associated with a given Markov measure $\mathbb{P}$, recalling that
for a general measurable spaces $\left(X,\mathcal{A}\right)$ and
$\left(Y,\mathcal{B}\right)$, a regular conditional probability in
the sense of \citet{breiman-1968} is a function $\nu:X\times\mathcal{B}\rightarrow\left[0,1\right]$
such that $v\left(\cdot,B\right)$ is $\mathcal{A}-$measurable and
$\nu\left(x,\cdot\right)$ is a probability measure on $\mathcal{B}$.
\begin{defn}[Forward and backward transition kernel]
 Fix $0\leq s\leq t\leq1$ and a Markov measure $\mathbb{P}$. For
$x\in\Omega_{s}$ and $A\in\mathcal{F}_{t}$, the forward transition
kernel $P_{s,t}\left(x,A\right)$ associated with $\mathbb{P}$ is
the regular conditional probability
\[
P_{s,t}\left(x,A\right)=\mathbb{P}\left(A\mid X_{s}=x\right)
\]
Similarly, for $y\in\Omega_{t}$ and $B\in\mathcal{F}_{s}$, the backward
transition kernel $P_{s,t}^{*}\left(B,y\right)$ is the regular conditional
probability (with swapped arguments)
\[
P_{s,t}^{*}\left(B,y\right)=\mathbb{P}\left(B\mid X_{t}=y\right)
\]
Of course, these kernels satisfy Chapman-Kolmogorov relation, so that
for any $0\leq s\leq t\leq u\leq1$, 
\begin{eqnarray*}
P_{s,u}\left(x,\cdot\right) & = & \int_{\Omega_{t}}P_{s,t}\left(x,dy\right)P_{t,u}\left(y,\cdot\right)\\
P_{s,u}^{*}\left(\cdot,z\right) & = & \int_{\Omega_{t}}P_{s,t}^{*}\left(\cdot,x\right)P_{t,u}^{*}\left(dx,z\right)
\end{eqnarray*}
for $x$, $\mathbb{P}_{s}-a.e.$, and $z$, $\mathbb{P}_{u}-a.e.$ 

Finally, we present a well-known and important result in the theory
of Markov measures.\end{defn}
\begin{thm}
\label{thm:markov-construction-thm}Fix $0\leq s\leq t\leq u\leq1$.
Let $\mathbb{P}_{t}$ be a marginal probability measure and $P_{t,u}\left(x,\cdot\right)$
and $P_{s,t}^{*}\left(\cdot,y\right)$ be transition kernels for $\left(x,y\right)\in\Omega_{t}$.
Then, a probability measure $\mathbb{P}$ is the Markov measure with
the given marginal and transition kernels if and only if $\mathbb{P}$
is a probability measure having 
\[
\mathbb{P}_{s_{1},\dots,s_{m},t,u_{1},\dots,u_{n}}=P_{s_{1},s_{2}}^{*}\times\cdots\times P_{s_{k},t}^{*}\times\mathbb{P}_{t}\times P_{t,u_{1}}\times\cdots\times P_{u_{n-1},u_{n}}
\]
as its finite-dimensional projection, for any choice of $0\leq s_{1}\leq\cdots\leq s_{m}\leq t\leq u_{1}\leq\cdots\leq u_{n}$
and $m,n\geq1$. Note the notation is such that $\left(\mathbb{P}_{t}\times P_{t,s}\right)\left(dx\times dy\right)=\mathbb{P}_{t}\left(dx\right)P_{t,s}\left(x,dy\right)$.
\end{thm}
This result says that there is one and only one Markov process with
a marginal distribution at $t\in\left[0,1\right]$ and transition
kernels from $t$. In particular, it allows us to construct a Markov
measure simply by specifying a marginal measure and accompanying transition
kernels. Note that if a marginal measure is specified for $t=0$ or
$t=1$, only a single transition kernel (forward or backward, respectively)
is needed to construct a unique Markov measure.


\section{Markov Bridge Measures}

Equipped with a basic understanding of Markov measures, we move now
to the theory of Markov bridges. We fix $\mathbb{P}$ as a Markov
measure (alternatively, we construct such a measure using \prettyref{thm:markov-construction-thm}).
Note that $\mathbb{P}$ can be disintegrated as a mixture of measures
pinned at times $t=0$ and $t=1$ in the following way:
\begin{equation}
\mathbb{P}=\int_{\mathcal{F}_{0}\otimes\mathcal{F}_{1}}\mathbb{P}\left(\cdot\mid X_{0}=x,X_{1}=y\right)\mathbb{P}_{0,1}\left(dxdy\right)\label{eq:bridge-decomposition}
\end{equation}
Under some fairly general conditions, the measure $\mathbb{P}\left(\cdot\mid X_{0}=x,X_{1}=y\right)$
exists for all $\left(x,y\right)\in\Omega_{0}\times\Omega_{1}$ and
is defined everywhere (the earliest abstract exposition on the existence
of such measures can be found in \citet{fitz-pitman-1993}). We will
refer to such a measure as the bridge measure $\mathbb{P}^{x,y}$
of the Markov measure $\mathbb{P}$. 
\begin{prop}[Bridge measures of Markov measures are Markov]
\label{prop:bridge-measures-are-markov}Let $\mathbb{P}$ be a Markov
measure. Then, for any $\left(x,y\right)\in\Omega_{0}\times\Omega_{1}$,
the bridge measure $\mathbb{P}^{x,y}$ is also Markov.\end{prop}
\begin{proof}
Let $t\in I$, and $A\in\mathcal{F}_{:t}$ and $B\in\mathcal{F}_{t:}$
be two events. Then, 
\begin{eqnarray}
\mathbb{P}\left(A\cap B\mid X_{0},X_{t},X_{1}\right) & = & \mathbb{E}\left[\mathbf{1}_{A}\mathbf{1}_{B}\mid X_{0},X_{t},X_{1}\right]\nonumber \\
 & = & \mathbb{E}\left[\mathbf{1}_{B}\mathbb{E}\left[\mathbf{1}_{A}\mid X_{0},X_{t:}\right]\mid X_{0},X_{t},X_{1}\right]\nonumber \\
 & = & \mathbb{E}\left[\mathbf{1}_{A}\mid X_{0},X_{t}\right]\mathbb{E}\left[\mathbf{1}_{B}\mid X_{0},X_{t},X_{1}\right]\nonumber \\
 & = & \mathbb{P}\left(A\mid X_{0},X_{t}\right)\mathbb{P}\left(B\mid X_{0},X_{t},X_{1}\right)\label{eq:bridge-is-markov-helper}
\end{eqnarray}
Note also that $\mathbb{P}\left(A\mid X_{0},X_{t}\right)=\mathbb{P}\left(A\mid X_{0},X_{t},X_{1}\right)$,
which along with \eqref{eq:bridge-is-markov-helper}, gives 
\[
\mathbb{P}^{X_{0},X_{1}}\left(A\cap B\mid X_{t}\right)=\mathbb{P}^{X_{0},X_{1}}\left(A\mid X_{t}\right)\mathbb{P}^{X_{0},X_{1}}\left(B\mid X_{t}\right)
\]
which shows that a particular bridge measure of a Markov measure is
itself Markov. Since $X_{0}$ and $X_{1}$ were arbitrary, we conclude
that any bridge $\mathbb{P}^{x,y}$ for $\left(x,y\right)\in\Omega_{0}\times\Omega_{1}$
of a Markov measure is itself Markov.
\end{proof}
This result can be understood on an intuitive level by noting that
if a measure is Markov, conditioning on the starting value of the
associated process  conditioning on the starting value of a Markov
process should not create dependence between an event before $t$
and an event after $t$ conditional on $X_{t}$, if the events were
independent conditional on $X_{t}$ to be begin with. By time-reversibility,
conditioning on the ending value should similarly not affect whether
the measure remains Markov. Conditioning on both the starting and
ending value then, {[}FLAG: INSERT INTUTION HERE{]}

Before continuing, we set a reference Markov measure $\mathbb{R}$
which is absolutely continuous with respect to the Lebesgue measure.
We assume this measure admits a family of bridge measures $\mathbb{R}^{x,y}$
that are defined everywhere, and the transition kernels of $\mathbb{R}$
are absolutely continuous with respect to the Lebesgue measure. Then,
by the Radon-Nikodym theorem and the usual assumptions \citep{nikodym-1930},
we can define the transition densities
\begin{eqnarray*}
r_{s,t}\left(x,y\right) & = & R_{s,t}\left(x,dy\right)/dy\\
r_{s,t}^{*}\left(x,y\right) & = & R_{s,t}^{*}\left(dx,y\right)/dx,\mbox{ }
\end{eqnarray*}
almost everywhere with respect to the appropriate measures.

We can also write $\mathbb{R}_{0}\left(dx\right)=r_{0}\left(x\right)dx$
where $r_{0}\left(x\right)=\int r_{0,1}^{*}\left(x,y\right)\mathbb{R}_{1}\left(dy\right)$
is the density of the marginal measure $\mathbb{R}_{0}$ with respect
to the Lebesgue measure, and define the density $r_{1}\left(x\right)$
similarly using the forward transition density. For convenience, we
will write $\mathbb{R}_{0,1}\left(dxdy\right)=c\left(x,y\right)dxdy$,
defining $c\left(x,y\right)=r\left(y,1\mid x,0\right)r_{0}\left(x\right)=r^{*}\left(x,0\mid y,1\right)r_{1}\left(y\right)$
as the density of the joint marginal measure $\mathbb{R}_{0,1}$ with
respect to the Lebesgue measure. 

With these densities in hand, we may state the following result.
\begin{lem}
\label{lem:endpoint-dominating-lemma}The probability measure $R_{0,t}^{*}\left(\cdot,z\right)\times R_{t,1}\left(z,\cdot\right)$
is dominated by $\mathbb{R}_{0,1}$ for $z$, $\mathbb{R}_{t}-a.e.$
Accordingly, the density of $R_{0,t}^{*}\left(\cdot,z\right)\times R_{t,1}\left(z,\cdot\right)$
with respect to $\mathbb{R}_{0,1}$ is 
\[
\frac{R_{0,t}^{*}\left(dx,z\right)R_{t,1}\left(z,dy\right)}{\mathbb{R}_{0,1}\left(dxdy\right)}=\frac{r_{0,t}^{*}\left(x,z\right)r_{t,1}\left(z,y\right)}{c\left(x,y\right)}
\]
\end{lem}
\begin{proof}
It suffices to show that if $c\left(x,y\right)=0$, then $r_{0,t}^{*}\left(x,z\right)r_{t,1}\left(z,y\right)=0$,
for any $z$, $\mathbb{R}_{t}-a.e.$ Note that 
\begin{eqnarray*}
\mathbb{R}_{0,1}\left(dxdy\right) & = & \int_{\Omega_{t}}\mathbb{R}_{0,t,1}\left(dxdzdy\right)\\
 & = & \int_{\Omega_{t}}R_{0,t}^{*}\left(dx,z\right)\mathbb{R}_{t}\left(dz\right)R_{t,1}\left(z,dy\right)\\
 & = & \int_{\Omega_{t}}r_{0,t}^{*}\left(x,z\right)\mathbb{R}_{t}\left(dz\right)r_{t,1}\left(z,y\right)dxdy\\
 & = & c\left(x,y\right)dxdy
\end{eqnarray*}
where the last equality is by definition of $c\left(x,y\right)$ as
the density of $\mathbb{R}_{0,1}$ with respect to the Lebesgue measure.
This gives 
\[
c\left(x,y\right)=\int_{\Omega_{t}}r_{0,t}^{*}\left(x,z\right)\mathbb{R}_{t}\left(dz\right)r_{t,1}\left(z,y\right)
\]
Since $\mathbb{R}_{t}\left(dz\right)$ is positive $\mathbb{R}_{t}-a.e.$,
we see that $c\left(x,y\right)=0$ necessarily implies $r_{0,t}^{*}\left(x,z\right)r_{t,1}\left(z,y\right)$
for $z$, $\mathbb{R}_{t}-a.e.$ as desired. By the Radon-Nikodym
theorem, the density of $R_{0,t}^{*}\left(dx,z\right)R_{t,1}\left(z,dy\right)$
with respect to $\mathbb{R}_{0,1}$ is therefore 
\[
\frac{R_{0,t}^{*}\left(dx,z\right)R_{t,1}\left(z,dy\right)}{\mathbb{R}_{0,1}\left(dxdy\right)}=\frac{r_{0,t}^{*}\left(x,z\right)r_{t,1}\left(z,y\right)}{c\left(x,y\right)}
\]
as desired.
\end{proof}
We now present the major result of this chapter, which relates a Markov
bridge measure explicitly to its reference measure.
\begin{thm}
\label{thm:density-of-bridge}For all $0<t<1$, all $\left(x,y\right)\in\Omega_{0}\times\Omega_{1}$,
and any $z$, $\mathbb{R}_{t}-a.e.$, the bridge measure of $\mathbb{R}$
restricted to $t$, $\mathbb{R}_{t}^{x,y}$, is dominated by $\mathbb{R}_{t}$.
The density of the marginal bridge measure $\mathbb{R}^{x,y}$ of
$\mathbb{R}$ with respect to $\mathbb{R}$ at $t$ is given by 
\[
\frac{\mathbb{R}_{t}^{x,y}\left(dz\right)}{\mathbb{R}_{t}\left(dz\right)}=\frac{r_{0,t}^{*}\left(x,z\right)r_{t,1}\left(z,y\right)}{c\left(x,y\right)}
\]
\end{thm}
\begin{proof}
{[}ARE YOU SURE YOU PROVED THAT IT IS DOMINATED?)Consider an event
$A\in\mathcal{F}_{t}$. First, note $\mathbb{R}_{t}^{x,y}\left(A\right)=\mathbb{E}_{\mathbb{R}}\left[\mathbf{1}_{A}\mid X_{0},X_{1}\right]$.
Thus we consider any two functions $f,g$ (subject to some boundedness
and measurability constraints), and write
\begin{eqnarray}
 &  & \mathbb{E}_{\mathbb{R}}\left[f\left(X_{0}\right)g\left(X_{1}\right)\mathbb{E}_{\mathbb{R}}\left[\mathbf{1}_{A}\mid X_{0},X_{1}\right]\right]\label{eq:bridge-thm-start}\\
 & = & \mathbb{E}_{\mathbb{R}}\left[f\left(X_{0}\right)\mathbf{1}_{A}g\left(X_{1}\right)\right]\nonumber \\
 & = & \mathbb{E}_{\mathbb{R}}\left[\mathbb{E}_{\mathbb{R}}\left[f\left(X_{0}\right)\mid X_{t}\right]\mathbf{1}_{A}\mathbb{E}_{\mathbb{R}}\left[g\left(X_{1}\right)\mid X_{t}\right]\right]\label{eq:bridge-thm-expectation-split}
\end{eqnarray}
We note that 
\begin{eqnarray*}
\mathbb{E}_{\mathbb{R}}\left[f\left(X_{0}\right)\mid X_{t}\right] & = & \int_{\Omega_{0}}f\left(x\right)R_{0,t}^{*}\left(dx,X_{t}\right)\\
\mathbb{E}_{\mathbb{R}}\left[g\left(X_{1}\right)\mid X_{t}\right] & = & \int_{\Omega_{1}}g\left(y\right)R_{t,1}\left(dy,X_{t}\right)
\end{eqnarray*}
and substitute these identities into \eqref{eq:bridge-thm-expectation-split}
to find
\begin{equation}
\mathbb{E}_{\mathbb{R}}\left[\mathbf{1}_{A}\int f\left(x\right)g\left(y\right)R_{0,t}^{*}\left(dx,X_{t}\right)R_{t,1}\left(dy,X_{t}\right)\right]\label{eq:bridge-thm-integral-pre-rewrite}
\end{equation}
 By \prettyref{lem:endpoint-dominating-lemma}, we can re-write the
integral in \eqref{eq:bridge-thm-integral-pre-rewrite} with respect
to $\mathbb{R}_{0,1}$ as follows:
\begin{eqnarray}
 &  & \mathbb{E}_{\mathbb{R}}\left[\mathbf{1}_{A}\int f\left(x\right)g\left(y\right)\frac{r_{0,t}^{*}\left(x,X_{t}\right)r_{t,1}\left(X_{t},y\right)}{c\left(x,y\right)}\mathbb{R}_{0,1}\left(dxdy\right)\right]\nonumber \\
 & = & \int f\left(x\right)g\left(y\right)\mathbb{E}_{\mathbb{R}}\left[\mathbf{1}_{A}\frac{r_{0,t}^{*}\left(x,X_{t}\right)r_{t,1}\left(X_{t},y\right)}{c\left(x,y\right)}\right]\mathbb{R}_{0,1}\left(dxdy\right)\label{eq:bridge-thm-done}
\end{eqnarray}
Since \eqref{eq:bridge-thm-start} is equal to \eqref{eq:bridge-thm-done}
for any functions $f,g$, it must be true that
\[
\mathbb{E}_{\mathbb{R}}\left[\mathbf{1}_{A}\mid X_{0},X_{1}\right]=\mathbb{E}_{\mathbb{R}}\left[\mathbf{1}_{A}\frac{r_{0,t}^{*}\left(x,X_{t}\right)r_{t,1}\left(X_{t},y\right)}{c\left(x,y\right)}\right]
\]
which, since $A$ was arbitrary, implies that
\[
\mathbb{R}_{t}^{x,y}\left(dz\right)=\frac{r_{0,t}^{*}\left(x,z\right)r_{t,1}\left(z,y\right)}{c\left(x,y\right)}\mathbb{R}_{t}\left(dz\right)
\]
for $z$, $\mathbb{R}_{t}-a.e.$ as desired. 
\end{proof}
This result is easily generalized to hold for any restriction $\mathbb{R}_{s:t}$
for $0<s\leq t<1$, as presented in \citet{leonard-2014}. 

\prettyref{thm:density-of-bridge} is useful because it gives the
density of the bridge measure $\mathbb{R}^{x,y}$ with respect to
the reference measure $\mathbb{R}$ at some time $0<t<1$; since we
know that $\mathbb{R}$ is absolutely continuous with respect to the
Lebesgue measure, we can therefore recover the density of the bridge
measure $\mathbb{R}_{t}^{x,y}$ with respect to the Lebesgue measure. 


\section{Summary}

This chapter began with an introduction of Markov measures and the
statement of \autoref{thm:markov-construction-thm}, \autoref{thm:markov-construction-thm}which
allows for the creation of a unique Markov measure $\mathbb{R}$ from
an arbitrary marginal measure $\mathbb{R}_{0}$ and a transition kernel
$R_{0,t}\left(x,\cdot\right)$. Then, using \autoref{thm:density-of-bridge},
we can find the density at $t$ of the associated bridge measure $\mathbb{R}^{x,y}$,
which itself is Markov by \autoref{prop:bridge-measures-are-markov}.

\bibliographystyle{plainnat}
\bibliography{Bibliography}

\end{document}
