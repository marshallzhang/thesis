#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass classicthesis
\use_default_options true
\maintain_unincluded_children false
\language american
\language_package default
\inputencoding default
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type numerical
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter*
Abstract
\end_layout

\begin_layout Standard
This thesis investigates a novel (to the best of our knowledge) and natural
 generalization of the theory of maximum likelihood estimation over discretely
 observed data from continuous-time stochastic processes.
 In particular, we propose a Kullback-Liebler divergence minimizing estimator
 as the appropriate estimator for inference when given distributional data
 i.e.
 when given the distribution of, as opposed to observations of, a diffusion
 process at discrete points in time.
 Examples of such data include the probabilistic forecasts frequently made
 in macroeconomics or meteorology.
 We characterize the proposed estimator and develop a Monte Carlo expectation-ma
ximization algorithm to carry out inference on distributional data.
 We also develop approximate and exact samplers for a certain class of generaliz
ed diffusion bridges.
 These samplers are not only of independent interest, but also necessary
 for implementing the expectation-maximization algorithm.
\end_layout

\begin_layout Standard
Empirically, we validate the correctness of the proposed methods and demonstrate
 their robustness to various assumptions made in their derivation.
 Finally, we use the methods developed to impute distributions between probabili
stic forecasts of inflation expectations, and show this imputation scheme
 reduces mean out-of-sample Kullback-Liebler divergence from the truth by
 up to a third relative to a baseline imputation scheme.
\end_layout

\end_body
\end_document
